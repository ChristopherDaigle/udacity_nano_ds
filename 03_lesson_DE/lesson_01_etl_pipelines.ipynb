{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pipelines: ETL vs ELT\n",
    "Data pipeline is a generic term for moving data from one place to another. For example, it could be moving data from one server to another server.\n",
    "\n",
    "## ETL\n",
    "An [ETL pipeline](https://en.wikipedia.org/wiki/Extract,_transform,_load) is a specific kind of data pipeline and very common. ETL stands for Extract, Transform, Load. Imagine that you have a database containing web [log data](https://en.wikipedia.org/wiki/Log_file). Each entry contains the IP address of a user, a timestamp, and the link that the user clicked.\n",
    "\n",
    "What if your company wanted to run an analysis of links clicked by city and by day? You would need another data set that maps IP address to a city, and you would also need to extract the day from the timestamp. With an ETL pipeline, you could run code once per day that would extract the previous day's log data, map IP address to city, aggregate link clicks by city, and then load these results into a new database. That way, a data analyst or scientist would have access to a table of log data by city and day. That is more convenient than always having to run the same complex data transformations on the raw web log data.\n",
    "\n",
    "Before cloud computing, businesses stored their data on large, expensive, private servers. Running queries on large data sets, like raw web log data, could be expensive both economically and in terms of time. But data analysts might need to query a database multiple times even in the same day; hence, pre-aggregating the data with an ETL pipeline makes sense.\n",
    "\n",
    "## ELT\n",
    "ELT (Extract, Load, Transform) pipelines have gained traction since the advent of cloud computing. Cloud computing has lowered the cost of storing data and running queries on large, raw data sets. Many of these cloud services, like [Amazon Redshift](https://aws.amazon.com/redshift/), [Google BigQuery](https://cloud.google.com/bigquery/), or [IBM Db2](https://www.ibm.com/cloud/db2-warehouse-on-cloud) can be queried using SQL or a SQL-like language. With these tools, the data gets extracted, then loaded directly, and finally transformed at the end of the pipeline.\n",
    "\n",
    "However, ETL pipelines are still used even with these cloud tools. Oftentimes, it still makes sense to run ETL pipelines and store data in a more readable or intuitive format. This can help data analysts and scientists work more efficiently as well as help an organization become more data driven."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outline of the Lesson\n",
    "1. Extract data from different sources such as:\n",
    "\n",
    ">* csv files\n",
    ">* json files\n",
    ">* APIs\n",
    "\n",
    "2. Transform data\n",
    "\n",
    ">* combining data from different sources\n",
    ">* data cleaning\n",
    ">* data types\n",
    ">* parsing dates\n",
    ">* file encodings\n",
    ">* missing data\n",
    ">* duplicate data\n",
    ">* dummy variables\n",
    ">* remove outliers\n",
    ">* scaling features\n",
    ">* engineering features\n",
    "\n",
    "3. Load\n",
    "\n",
    ">* send the transformed data to a database\n",
    "\n",
    "4. ETL Pipeline\n",
    "\n",
    ">* code an ETL pipeline\n",
    "\n",
    "This lesson contains many Jupyter notebook exercises where you can practice the different parts of an ETL pipeline. Some of the exercises are challenging, but they also contain hints to help you get through them. You'll notice that the \"transformation\" section is relatively long. You'll oftentimes hear data scientists say that cleaning and transforming data is how they spend a majority of their time. This lesson reflects that reality.\n",
    "\n",
    "#### Big Data Courses at Udacity\n",
    "\"Big Data\" gets a lot of buzz these days, and it is definitely an important part of a data engineer's and, sometimes, a data scientists's work. With \"Big Data\", you need special tools that can work on distributed computer systems.\n",
    "\n",
    "This ETL course focuses on the practical fundamentals of ETL. Hence, you'll be working with a local data set so that you do not need to worry about learning a new tool. Udacity has other courses where the primary focus is on tools used for distributed data sets.\n",
    "\n",
    "Here are links to other big data courses at Udacity:\n",
    "* [Intro to Hadoop and MapReduce](https://www.udacity.com/course/intro-to-hadoop-and-mapreduce--ud617)\n",
    "* [Deploying a Hadoop Cluster](https://www.udacity.com/course/deploying-a-hadoop-cluster--ud1000)\n",
    "* [Real-time Analytics with Apache Storm](https://www.udacity.com/course/real-time-analytics-with-apache-storm--ud381)\n",
    "* [Big Data Analytics in Health Care](https://www.udacity.com/course/big-data-analytics-in-healthcare--ud758)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## World Bank Data\n",
    "In the next section, you'll find a series of exercises. These are relatively brief and focus on extracting, or in other words, reading in data from different sources. The goal is to familiarize yourself with different types of files and see how the same data can be formatted in different ways. This lesson assumes you have experience with pandas and basic programming skills.\n",
    "[VIDEO](https://youtu.be/lNPzOLzZVbw)\n",
    "\n",
    "This lesson uses data from the World Bank. The data comes from two sources:\n",
    "1. [World Bank Indicator Data](https://data.worldbank.org/indicator) - This data contains socio-economic indicators for countries around the world. A few example indicators include population, arable land, and central government debt.\n",
    "\n",
    "2. [World Bank Project Data](https://datacatalog.worldbank.org/dataset/world-bank-projects-operations) - This data set contains information about World Bank project lending since 1947.\n",
    "Both of these data sets are available in different formats including as a csv file, json, or xml. You can download the csv directly or you can use the World Bank APIs to extract data from the World Bank's servers. You'll be doing both in this lesson.\n",
    "\n",
    "The end goal is to clean these data sets and bring them together into one table. As you'll see, it's not as easy as one might hope. By the end of the lesson, you'll have written an ETL pipeline to extract, transform, and load this data into a new database.\n",
    "\n",
    "The goal of the lesson is to combine these data sets together so that you can run a linear regression model predicting World Bank Project total costs. You will not actually build the model; instead, you will get the data ready so that a data analyst or data scientist could more easily build the model.\n",
    "\n",
    "### How to Tackle the Exercises\n",
    "This course assumes you have experience manipulating data with the Pandas library, which is covered in the data analyst nanodegree. Some of these transformation exercises are challenging. The most challenging exercises are marked (challenging). If an exercise is marked as a challenge, it means you’ll get something out of solving it, but it’s not essential for understanding the lesson material or for getting through the final project at the end of this data engineering course.\n",
    "\n",
    "Throughout the exercises, you might have to read the pandas documentation or search outside the classroom for how to do a certain processing technique. That is not just expected but also **encouraged**. As a data scientist professional, you will oftentimes have to research how to do something on your own much like what software engineers do. See this answer on [Quora about how often do people use stackoverflow when working on data science projects?](https://www.quora.com/How-often-do-people-use-stackoverflow-when-working-on-data-science-projects)\n",
    "\n",
    "Use Google and other search engines when you're not sure how to do something!\n",
    "\n",
    "### What You Will do in the Next Section\n",
    "In the next section of the lesson, you'll learn about the extract portion of an ETL pipeline. You’ll get practice with a series of exercises. These exercises are relatively brief and focus on extracting, or in other words, reading in data from different sources. The goal is to familiarize yourself with different types of files and see how the same data can be formatted in different ways.\n",
    "\n",
    "For a review of pandas, click on the \"Extracurricular\" section of the classroom. Open the *Prerequisite: Python for Data Analysis course, and go to Lesson 7: Pandas*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract\n",
    "[VIDEO](https://youtu.be/4dKG_08zMm4)\n",
    "\n",
    "* Extraction: pulling and loading data from different sources\n",
    "\n",
    "### Overview of the Extract Part of the Lesson\n",
    "[VIDEO](https://youtu.be/Bbj8rQRRVoM)\n",
    "\n",
    "### Summary of the data file types you'll work with\n",
    "**CSV files**\n",
    "\n",
    "CSV stands for comma-separated values. These types of files separate values with a comma, and each entry is on a separate line. Oftentimes, the first entry will contain variable names. Here is an example of what CSV data looks like. This is an abbreviated version of the first three lines in the World Bank projects data csv file.\n",
    "```\n",
    "id,regionname,countryname,prodline,lendinginstr\n",
    "P162228,Other,World;World,RE,Investment Project Financing\n",
    "P163962,Africa,Democratic Republic of the Congo;Democratic Republic of the Congo,PE,Investment Project Financing\n",
    "```\n",
    "**JSON**\n",
    "\n",
    "JSON is a file format with key/value pairs. It looks like a Python dictionary. The exact same CSV file represented in JSON could look like this:\n",
    "```python\n",
    "[{\"id\":\"P162228\",\"regionname\":\"Other\",\"countryname\":\"World;World\",\"prodline\":\"RE\",\"lendinginstr\":\"Investment Project Financing\"},{\"id\":\"P163962\",\"regionname\":\"Africa\",\"countryname\":\"Democratic Republic of the Congo;Democratic Republic of the Congo\",\"prodline\":\"PE\",\"lendinginstr\":\"Investment Project Financing\"},{\"id\":\"P167672\",\"regionname\":\"South Asia\",\"countryname\":\"People\\'s Republic of Bangladesh;People\\'s Republic of Bangladesh\",\"prodline\":\"PE\",\"lendinginstr\":\"Investment Project Financing\"}]\n",
    "```\n",
    "Each line in the data is inside of a squiggly bracket {}. The variable names are the keys, and the variable values are the values.\n",
    "\n",
    "There are other ways to organize JSON data, but the general rule is that JSON is organized into key/value pairs. For example, here is a different way to represent the same data using JSON:\n",
    "```python\n",
    "{\"id\":{\"0\":\"P162228\",\"1\":\"P163962\",\"2\":\"P167672\"},\"regionname\":{\"0\":\"Other\",\"1\":\"Africa\",\"2\":\"South Asia\"},\"countryname\":{\"0\":\"World;World\",\"1\":\"Democratic Republic of the Congo;Democratic Republic of the Congo\",\"2\":\"People\\'s Republic of Bangladesh;People\\'s Republic of Bangladesh\"},\"prodline\":{\"0\":\"RE\",\"1\":\"PE\",\"2\":\"PE\"},\"lendinginstr\":{\"0\":\"Investment Project Financing\",\"1\":\"Investment Project Financing\",\"2\":\"Investment Project Financing\"}}\n",
    "```\n",
    "\n",
    "**XML**\n",
    "\n",
    "Another data format is called XML (Extensible Markup Language). XML is very similar to HTML at least in terms of formatting. The main difference between the two is that HTML has pre-defined tags that are standardized. In XML, tags can be tailored to the data set. Here is what this same data would look like as XML.\n",
    "\n",
    "```html\n",
    "<ENTRY>\n",
    "  <ID>P162228</ID>\n",
    "  <REGIONNAME>Other</REGIONNAME>\n",
    "  <COUNTRYNAME>World;World</COUNTRYNAME>\n",
    "  <PRODLINE>RE</PRODLINE>\n",
    "  <LENDINGINSTR>Investment Project Financing</LENDINGINSTR>\n",
    "</ENTRY>\n",
    "<ENTRY>\n",
    "  <ID>P163962</ID>\n",
    "  <REGIONNAME>Africa</REGIONNAME>\n",
    "  <COUNTRYNAME>Democratic Republic of the Congo;Democratic Republic of the Congo</COUNTRYNAME>\n",
    "  <PRODLINE>PE</PRODLINE>\n",
    "  <LENDINGINSTR>Investment Project Financing</LENDINGINSTR>\n",
    "</ENTRY>\n",
    "<ENTRY>\n",
    "  <ID>P167672</ID>\n",
    "  <REGIONNAME>South Asia</REGIONNAME>\n",
    "  <COUNTRYNAME>People's Republic of Bangladesh;People's Republic of Bangladesh</COUNTRYNAME>\n",
    "  <PRODLINE>PE</PRODLINE>\n",
    "  <LENDINGINSTR>Investment Project Financing</LENDINGINSTR>\n",
    "</ENTRY>\n",
    "```\n",
    "XML is falling out of favor especially because JSON tends to be easier to navigate; however, you still might come across XML data. The World Bank API, for example, can return either XML data or JSON data. From a data perspective, the process for handling HTML and XML data is essentially the same.\n",
    "\n",
    "**SQL databases**\n",
    "\n",
    "SQL databases store data in tables using [primary and foreign keys](https://docs.microsoft.com/en-us/sql/relational-databases/tables/primary-and-foreign-key-constraints?view=sql-server-2017). In a SQL database, the same data would look like this:\n",
    "\n",
    "| id      | regionname | countryname                                                       | prodline | lendinginstr                 |\n",
    "|---------|------------|-------------------------------------------------------------------|----------|------------------------------|\n",
    "| P162228 | Other      | World;World                                                       | RE       | Investment Project Financing |\n",
    "| P163962 | Africa     | Democratic Republic of the Congo;Democratic Republic of the Congo | PE       | Investment Project Financing |\n",
    "| P167672 | South Asia | People's Republic of Bangladesh;People's Republic of Bangladesh   | PE       | Investment Project Financing |\n",
    "\n",
    "**Text Files**\n",
    "\n",
    "This course won't go into much detail about text data. There are other Udacity courses, namely on natural language processing, that go into the details of processing text for machine learning.\n",
    "\n",
    "Text data present their own issues. Whereas CSV, JSON, XML, and SQL data are organized with a clear structure, text is more ambiguous. For example, the World Bank project data country names are written like this\n",
    "```\n",
    "Democratic Republic of the Congo;Democratic Republic of the Congo\n",
    "```\n",
    "In the World Bank Indicator data sets, the [Democratic Republic of the Congo](https://data.worldbank.org/country/congo-dem-rep?view=chart) is represented by the abbreviation \"Congo, Dem. Rep.\" You'll have to clean these country names to join the data sets together.\n",
    "\n",
    "**Extracting Data from the Web**\n",
    "\n",
    "In this lesson, you'll see how to extract data from the web using an APIs (Application Programming Interface). APIs generally provide data in either JSON or XML format.\n",
    "\n",
    "Companies and organizations provide APIs so that programmers can access data in an official, safe way. APIs allow you to download, and sometimes even upload or modify, data from a web server without giving you direct access."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Data\n",
    "Text data can come in different forms. A text file (`.txt`), for example, will contain only text. As another example, a data set might contain text for one or more variables. In the world bank projects data set, the regionname, countryname, theme and sector variables contain text.\n",
    "\n",
    "Analyzing text is a big topic that is covered in other Udacity courses on Natural Language Processing. For the purposes of this lesson on ETL pipelines, pandas is automatically \"extracting\" text data when reading in a csv, xml or json file.\n",
    "\n",
    "Text data will be more important in the Transform stage of an ETL pipeline, which comes later in the lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: APIs\n",
    "\n",
    "Instead of downloading World Bank data via a csv file, you're going to download the data using the World Bank APIs. The purpose of this exercise is to gain experience with another way of extracting data.\n",
    "\n",
    "API is an acronym that stands for application programming interface. API’s provide a standardized way for two applications to talk to each other. In this case, the applications communicating with each other are the server application where World Bank stores data and your Jupyter notebook.\n",
    "\n",
    "If you wanted to pull data directly from the World Bank’s server, you’d have to know what database system the World Bank was using. You’d also need permission to log in directly to the server, which would be a security risk for the World Bank. And if the World Bank ever migrated its data to a new system, you would have to rewrite all of your code again. The API allows you to execute code on the World Bank server without getting direct access.\n",
    "\n",
    "### Before there were APIs\n",
    "\n",
    "Before there were APIs, there was web scraping. People would download html directly from a website and then parse the results programatically. This practice is in a legal grey area. One reason that APIs became popular was so that companies could provide data to users and discourage web scraping.\n",
    "\n",
    "Here are a few articles about the legality of web scraping.\n",
    "\n",
    "* [QVC Can't Stop Web Scraping](https://www.forbes.com/sites/ericgoldman/2015/03/24/qvc-cant-stop-web-scraping/#120db59b3ca3)\n",
    "* [Quora - Legality of Web Scraping](https://www.quora.com/What-is-the-legality-of-web-scraping)\n",
    "\n",
    "All sorts of companies have public facing APIs including Facebook, Twitter, Google and Pinterest. You can pull data from these companies to create your own applications.\n",
    "\n",
    "In this notebook, you’ll get practice using Python to pull data from the World Bank indicators API.\n",
    "\n",
    "Here are links to information about the World Bank indicators and projects APIs if you want to learn more:\n",
    "* [World Bank Indicators API](world bank projects api)\n",
    "* [World Bank Projects API](http://search.worldbank.org/api/v2/projects)\n",
    "\n",
    "### Using APIs\n",
    "\n",
    "In general, you access APIs via the web using a web address. Within the web address, you specify the data that you want. To know how to format the web address, you need to read an API's documentation. Some APIs also require that you send login credentials as part of your request. The World Bank APIs are public and do not require login credentials.\n",
    "\n",
    "The Python requests library makes working with APIs relatively simple.\n",
    "\n",
    "### Example Indicators API\n",
    "\n",
    "Run the code example below to request data from the World Bank Indicators API. According to the documntation, you format your request url like so:\n",
    "\n",
    "`http://api.worldbank.org/v2/countries/` + list of country abbreviations separated by ; + `/indicators/` + indicator name + `?` + options\n",
    "\n",
    "where options can include\n",
    "* per_page - number of records to return per page\n",
    "* page - which page to return - eg if there are 5000 records and 100 records per page\n",
    "* date - filter by dates\n",
    "* format - json or xml\n",
    " \n",
    " and a few other options that you can read about [here](https://datahelpdesk.worldbank.org/knowledgebase/articles/898581-api-basic-call-structure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "url = 'http://api.worldbank.org/v2/countries/br;cn;us;de/indicators/SP.POP.TOTL/?format=json&per_page=1000'\n",
    "r = requests.get(url)\n",
    "# r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This json data isn't quite ready for a pandas data frame. Notice that the json response is a list with two entries. The first entry is \n",
    "```\n",
    "{'lastupdated': '2018-06-28',\n",
    "  'page': 1,\n",
    "  'pages': 1,\n",
    "  'per_page': 1000,\n",
    "  'total': 232}\n",
    "```\n",
    "\n",
    "That first entry is meta data about the results. For example, it says that there is one page returned with 232 results. \n",
    "\n",
    "The second entry is another list containing the data. This data would need some cleaning to be used in a pandas data frame. That would happen later in the transformation step of an ETL pipeline. Run the cell below to read the results into a dataframe and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indicator</th>\n",
       "      <th>country</th>\n",
       "      <th>countryiso3code</th>\n",
       "      <th>date</th>\n",
       "      <th>value</th>\n",
       "      <th>unit</th>\n",
       "      <th>obs_status</th>\n",
       "      <th>decimal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'id': 'SP.POP.TOTL', 'value': 'Population, to...</td>\n",
       "      <td>{'id': 'BR', 'value': 'Brazil'}</td>\n",
       "      <td>BRA</td>\n",
       "      <td>2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'id': 'SP.POP.TOTL', 'value': 'Population, to...</td>\n",
       "      <td>{'id': 'BR', 'value': 'Brazil'}</td>\n",
       "      <td>BRA</td>\n",
       "      <td>2018</td>\n",
       "      <td>209469333.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'id': 'SP.POP.TOTL', 'value': 'Population, to...</td>\n",
       "      <td>{'id': 'BR', 'value': 'Brazil'}</td>\n",
       "      <td>BRA</td>\n",
       "      <td>2017</td>\n",
       "      <td>207833831.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'id': 'SP.POP.TOTL', 'value': 'Population, to...</td>\n",
       "      <td>{'id': 'BR', 'value': 'Brazil'}</td>\n",
       "      <td>BRA</td>\n",
       "      <td>2016</td>\n",
       "      <td>206163058.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'id': 'SP.POP.TOTL', 'value': 'Population, to...</td>\n",
       "      <td>{'id': 'BR', 'value': 'Brazil'}</td>\n",
       "      <td>BRA</td>\n",
       "      <td>2015</td>\n",
       "      <td>204471769.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           indicator  \\\n",
       "0  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
       "1  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
       "2  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
       "3  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
       "4  {'id': 'SP.POP.TOTL', 'value': 'Population, to...   \n",
       "\n",
       "                           country countryiso3code  date        value unit  \\\n",
       "0  {'id': 'BR', 'value': 'Brazil'}             BRA  2019          NaN        \n",
       "1  {'id': 'BR', 'value': 'Brazil'}             BRA  2018  209469333.0        \n",
       "2  {'id': 'BR', 'value': 'Brazil'}             BRA  2017  207833831.0        \n",
       "3  {'id': 'BR', 'value': 'Brazil'}             BRA  2016  206163058.0        \n",
       "4  {'id': 'BR', 'value': 'Brazil'}             BRA  2015  204471769.0        \n",
       "\n",
       "  obs_status  decimal  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(r.json()[1]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some issues with this dataframe. The country and indicator variables don't look particularly useful in their current form. Again, dealing with those issues would come in the transformation phase of a pipeline, which comes later in the lesson.\n",
    "\n",
    "### Exercise Indicators API\n",
    "\n",
    "Use the Indicators API to request rural population data for Switzerland in the years 1995 through 2001. Here are a few helpful resources:\n",
    "* [documentation included how to filter by year](https://datahelpdesk.worldbank.org/knowledgebase/articles/898581-api-basic-call-structure)\n",
    "* [2-character iso country codes](https://www.nationsonline.org/oneworld/country_code_list.htm)\n",
    "* [search box for World Bank indicators](https://data.worldbank.org)\n",
    "\n",
    "To find the indicator code, first search for the indicator here: https://data.worldbank.org\n",
    "Click on the indicator name. The indicator code is in the url. For example, the indicator code for total population is SP.POP.TOTL, which you can see in the link [https://data.worldbank.org/indicator/SP.RUR.TOTL](https://data.worldbank.org/indicator/SP.RUR.TOTL)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page': 1,\n",
       "  'pages': 1,\n",
       "  'per_page': 50,\n",
       "  'total': 7,\n",
       "  'sourceid': '2',\n",
       "  'lastupdated': '2020-05-28'},\n",
       " [{'indicator': {'id': 'SP.RUR.TOTL', 'value': 'Rural population'},\n",
       "   'country': {'id': 'CH', 'value': 'Switzerland'},\n",
       "   'countryiso3code': 'CHE',\n",
       "   'date': '2001',\n",
       "   'value': 1924949,\n",
       "   'unit': '',\n",
       "   'obs_status': '',\n",
       "   'decimal': 0},\n",
       "  {'indicator': {'id': 'SP.RUR.TOTL', 'value': 'Rural population'},\n",
       "   'country': {'id': 'CH', 'value': 'Switzerland'},\n",
       "   'countryiso3code': 'CHE',\n",
       "   'date': '2000',\n",
       "   'value': 1912232,\n",
       "   'unit': '',\n",
       "   'obs_status': '',\n",
       "   'decimal': 0},\n",
       "  {'indicator': {'id': 'SP.RUR.TOTL', 'value': 'Rural population'},\n",
       "   'country': {'id': 'CH', 'value': 'Switzerland'},\n",
       "   'countryiso3code': 'CHE',\n",
       "   'date': '1999',\n",
       "   'value': 1897587,\n",
       "   'unit': '',\n",
       "   'obs_status': '',\n",
       "   'decimal': 0},\n",
       "  {'indicator': {'id': 'SP.RUR.TOTL', 'value': 'Rural population'},\n",
       "   'country': {'id': 'CH', 'value': 'Switzerland'},\n",
       "   'countryiso3code': 'CHE',\n",
       "   'date': '1998',\n",
       "   'value': 1884719,\n",
       "   'unit': '',\n",
       "   'obs_status': '',\n",
       "   'decimal': 0},\n",
       "  {'indicator': {'id': 'SP.RUR.TOTL', 'value': 'Rural population'},\n",
       "   'country': {'id': 'CH', 'value': 'Switzerland'},\n",
       "   'countryiso3code': 'CHE',\n",
       "   'date': '1997',\n",
       "   'value': 1875299,\n",
       "   'unit': '',\n",
       "   'obs_status': '',\n",
       "   'decimal': 0},\n",
       "  {'indicator': {'id': 'SP.RUR.TOTL', 'value': 'Rural population'},\n",
       "   'country': {'id': 'CH', 'value': 'Switzerland'},\n",
       "   'countryiso3code': 'CHE',\n",
       "   'date': '1996',\n",
       "   'value': 1866968,\n",
       "   'unit': '',\n",
       "   'obs_status': '',\n",
       "   'decimal': 0},\n",
       "  {'indicator': {'id': 'SP.RUR.TOTL', 'value': 'Rural population'},\n",
       "   'country': {'id': 'CH', 'value': 'Switzerland'},\n",
       "   'countryiso3code': 'CHE',\n",
       "   'date': '1995',\n",
       "   'value': 1854939,\n",
       "   'unit': '',\n",
       "   'obs_status': '',\n",
       "   'decimal': 0}]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the url ready\n",
    "countries = 'ch' # switzerland\n",
    "years = '1995:2001' # from 1995 through 2001\n",
    "indicator = 'SP.RUR.TOTL' # rural\n",
    "output_type = 'json' # get a json\n",
    "url = 'http://api.worldbank.org/v2/countries/{0}/indicators/{1}/?format={2}&date={3}'\\\n",
    ".format(countries, indicator, output_type, years)\n",
    "\n",
    "# send the request\n",
    "r = requests.get(url)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming Data\n",
    "\n",
    "* [Combining](https://github.com/ChristopherDaigle/udacity_nano_ds/blob/master/03_lesson_DE/ETLPipelines/5_combinedata_exercise/5_combining_data.ipynb) & [Cleaning Data](https://github.com/ChristopherDaigle/udacity_nano_ds/blob/master/03_lesson_DE/ETLPipelines/6_cleaningdata_exercise/6_cleaning_data.ipynb)\n",
    "* Working with Encodings\n",
    "* Removing duplicate rows\n",
    "* Create Dummy Variables\n",
    "* Remove Outliers\n",
    "* Normalize Data\n",
    "* Engineer New Features\n",
    "\n",
    "### Pandas Resources for Quick Review\n",
    "\n",
    "* [10 Minute Intro to Pandas](https://pandas.pydata.org/pandas-docs/stable/10min.html)\n",
    "* [Pandas Basic Functionality](https://pandas.pydata.org/pandas-docs/stable/basics.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Data\n",
    "There are some implementations of machine learning algorithms, such as [gradient boosting decision trees](https://xgboost.readthedocs.io/en/latest/) that can [handle missing values](https://github.com/dmlc/xgboost/issues/21).\n",
    "\n",
    "### Two Options for Handling: Delete or Impute\n",
    "\n",
    "1. Delete: remove data/missing data\n",
    "\n",
    ">* column if nearly all missing or seems to add no value\n",
    ">* row if nearly all missing or seems to add no value\n",
    "\n",
    "**NOTE:** when to delete is subjective and should be analyzed in some way, there may be information in those observations or columns being nearly totally null\n",
    "\n",
    "2. Impute: replace data/missing data\n",
    "\n",
    "Common methods:\n",
    "* Mean Substitution\n",
    "* Median Substitution\n",
    "* Mode Substitution\n",
    "* Forward or Backward Fill (especially for time ordered data)\n",
    "\n",
    "### When to Remove a Feature\n",
    "As mentioned in the video, if you have five categories, you only really need four features. For example, if the categories are \"agriculture\", \"banking\", \"retail\", \"roads\", and \"government\", then you only need four of those five categories for dummy variables. This topic is somewhat outside the scope of a data engineer.\n",
    "\n",
    "In some cases, you don't necessarily need to remove one of the features. It will depend on your application. In regression models, which use linear combinations of features, removing a dummy variable is important. For a decision tree, removing one of the variables is not needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers\n",
    "Q: How do you find outliers<br>\n",
    "Q: What do you do with them?\n",
    "\n",
    "* [scikit-learn novelty and outlier detection](http://scikit-learn.org/stable/modules/outlier_detection.html)\n",
    "* [statistical and machine learning methods for outlier detection](https://towardsdatascience.com/a-brief-overview-of-outlier-detection-techniques-1e0b2c19e561)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
