{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing Pipelines\n",
    "\n",
    "In this lesson, you'll be introduced to some of the steps involved in a NLP pipeline:\n",
    "\n",
    "1. Text Processing\n",
    "\n",
    ">* Cleaning\n",
    ">* Normalization\n",
    ">* Tokenization\n",
    ">* Stop Word Removal\n",
    ">* Part of Speech Tagging\n",
    ">* Named Entity Recognition\n",
    ">* Stemming and Lemmatization\n",
    "\n",
    "2. Feature Extraction\n",
    "\n",
    ">* Bag of Words\n",
    ">* TF-IDF\n",
    ">* Word Embeddings\n",
    "\n",
    "3. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How NLP Pipelines Work\n",
    "The 3 stages of an NLP pipeline are: Text Processing -> Feature Extraction -> Modeling.\n",
    "\n",
    "1. **Text Processing:** Take raw input text, clean it, normalize it, and convert it into a form that is suitable for feature extraction.\n",
    "\n",
    "2. **Feature Extraction:** Extract and produce feature representations that are appropriate for the type of NLP task you are trying to accomplish and the type of model you are planning to use.\n",
    "\n",
    "3. **Modeling:** Design a statistical or machine learning model, fit its parameters to training data, use an optimization procedure, and then use it to make predictions about unseen data.\n",
    "\n",
    "This process isn't always linear and may require additional steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1: Text Processing\n",
    "The first chunk of this lesson will explore the steps involved in text processing, the first stage of the NLP pipeline.\n",
    "\n",
    "* **Extracting plain text:** Textual data can come from a wide variety of sources: the web, PDFs, word documents, speech recognition systems, book scans, etc. Your goal is to extract plain text that is free of any source specific markup or constructs that are not relevant to your task.\n",
    "* **Reducing complexity:** Some features of our language like capitalization, punctuation, and common words such as a, of, and the, often help provide structure, but don't add much meaning. Sometimes it's best to remove them if that helps reduce the complexity of the procedures you want to apply later.\n",
    "\n",
    "In this lesson...\n",
    "> You'll prepare text data from different sources with the following text processing steps:\n",
    "\n",
    "1. **Cleaning** to remove irrelevant items, such as HTML tags\n",
    "2. **Normalizing** by converting to all lowercase and removing punctuation\n",
    "3. Splitting text into words or **tokens**\n",
    "4. Removing words that are too common, also known as **stop words**\n",
    "5. Identifying different **parts of speech** and **named entities**\n",
    "6. Converting words into their dictionary forms, using **stemming and lemmatization**\n",
    "\n",
    "After performing these steps, your text will capture the essence of what was being conveyed in a form that is easier to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Processing: Cleaning\n",
    "Let's walk through an example of cleaning text data from a popular source - the web. You'll be introduced to helpful tools in working with this data, including the `requests` library, **regular expressions**, and `Beautiful Soup`.\n",
    "\n",
    "**Documentation for Python Libraries:**\n",
    "* [Requests](http://docs.python-requests.org/en/master/user/quickstart/#make-a-request)\n",
    "* [Regular Expressions](https://docs.python.org/3/library/re.html)\n",
    "* [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXAMPLE:\n",
    "```python\n",
    "# import statements\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# fetch web page\n",
    "r = requests.get(\"https://www.udacity.com/courses/all\")\n",
    "r\n",
    ">>> <Response [200]>\n",
    "\n",
    "soup = BeautifulSoup(markup=r.text, features=\"lxml\")\n",
    "soup\n",
    ">>> <!DOCTYPE html>\n",
    ">>> <html lang=\"en-US\"><head>\n",
    ">>> <meta charset=\"utf-8\"/>\n",
    ">>> <script class=\"ng-star-inserted\" ...\n",
    ">>> ...\n",
    ">>> &q;type&q;:&q;category&q;,&q;matchCriteria&q;:{&q;withKey&q;\n",
    ">>> :&q;VR development&q;}}]}]}</script></body></html>\n",
    "        \n",
    "# Find all course summaries\n",
    "summaries = soup.find_all(\"div\", {\"class\": \"course-summary-card\"})\n",
    "print('Number of Courses:', len(summaries))\n",
    ">>> Number of Courses: 250\n",
    "\n",
    "# print the first summary in summaries\n",
    "print(summaries[0].prettify())\n",
    ">>> <div _ngcontent-sc154=\"\" class=\"...\">\n",
    ">>>  <ir-catalog-card _ngcontent-sc154=\"\" _nghost-sc157=\"\">\n",
    ">>>   <div _ngcontent-sc157=\"\" class=\"card-wrapper is-collapsed\">\n",
    ">>> ...\n",
    ">>> </div>\n",
    "\n",
    "# Extract course title\n",
    "summaries[0].select_one(\"h3\").get_text()\n",
    ">>> 'Applying Data Science to Product Management'\n",
    "\n",
    "# Extract school\n",
    "summaries[0].select_one(\"h4\").get_text().strip()\n",
    ">>> 'School of Business'\n",
    "\n",
    "# append name and school of each summary to courses list\n",
    "courses = []\n",
    "for summary in summaries:\n",
    "    name = summary.select_one(\"h3\").get_text()\n",
    "    school = summary.select_one(\"h4\").get_text().strip()\n",
    "    courses.append((school, name))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
