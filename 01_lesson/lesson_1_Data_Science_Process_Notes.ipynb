{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplified 4-Step Process for Modeling using Scikit-Learn\n",
    "1. Instantiate Model\n",
    "> `model = Classifier()`\n",
    "2. Fit model to training data\n",
    "> `model.fit(X_train, y_train)`\n",
    "3. Predict on test data with the fitted model\n",
    "> `pred_test = model.predict(X_test)`\n",
    "4. Score the model using a metric to evaluate how well it performs\n",
    "> `fbeta_score(y_test, pred_test, beta=0.5)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working With Missing Data\n",
    "1. Remove\n",
    "> We can remove (or “drop”) the rows or columns holding the missing values\n",
    "2. Impute\n",
    "> Replace with mean, median, mode of frequency, univariate linear regression, etc.\n",
    "3. Work Around\n",
    "> We can build models that work around them, and only use the information provided\n",
    "\n",
    "Resource: [How to Handle Missing Data](https://towardsdatascience.com/how-to-handle-missing-data-8646b18db0d4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: Removing\n",
    "1. Ask \"Why are the values missing\"\n",
    "> Removing data can lead to biased models\n",
    "\n",
    "Ex: If data is of survey nature, the types of questions NOT RESPONDED TO may indicate different types of respondents\n",
    "\n",
    "May be valuable to account for the number of, or which questions have, missing values for each observation:\n",
    "\n",
    "| Q1 | Q2  | Q3  | Missing |\n",
    "|----|-----|-----|---------|\n",
    "| 1  | Nan | 1   | 1       |\n",
    "| 4  | 4   | Nan | 1       |\n",
    "| 1  | 2   | 1   | 0       |\n",
    "\n",
    "### When is it ok to remove missing values?\n",
    "1. Data entry errors\n",
    "2. Mechanical errors\n",
    "3. Didn't need the data\n",
    "4. The missing data is in the column to be predicted\n",
    "5. There is no variablity in the observations\n",
    "\n",
    "### Other Considerations\n",
    "1. Drop observations\n",
    "2. Drop columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: Imputing\n",
    "\n",
    "Be very cautious of the BIAS you are imputing into any model that uses these imputed values.\n",
    "\n",
    "Though imputing values is very common, and often leads to better predictive power in machine learning models, it can lead to **over generalizations**\n",
    "\n",
    "* By imputing, you are diluting the importance of that feature\n",
    "* Variablity in features is what allows you to use them to predict another variable well\n",
    "\n",
    "**Common Methods:**\n",
    "1. Mean\n",
    "2. Median\n",
    "3. Mode\n",
    "> Especially with categorical data\n",
    "4. Impute 0 or $\\infty$\n",
    "> Small or large value to differentiate missing values from the others\n",
    "\n",
    "**More advanced:**\n",
    "1. [K-Nearest Neighbors](https://faculty.marshall.usc.edu/gareth-james/ISL/ISLR%20Seventh%20Printing.pdf)\n",
    "> Impute values based on features that are most similar\n",
    "2. [AMELIA](https://cran.r-project.org/web/packages/Amelia/Amelia.pdf)\n",
    "\n",
    "**PROS OF IMPUTING**\n",
    "* You **ARE NOT** removing rows\n",
    "\n",
    "**CONS OF IMPUTING**\n",
    "* You **ARE** diluting the power of your features to predict well by reducing variability in those features\n",
    "\n",
    "Note that in the image, the pink values were missing and replaced with the mean values in the column. However, `child height` at `42` and at `57` are vastly different. Because of imputation though, these two observations are identical aside from the value to be predicted\n",
    "\n",
    "<img src='impute_0.png'>\n",
    "\n",
    "In general, you should try to be more careful with missing data in understanding the real world implications and reasons for why the missing values exist. At the same time, these solutions are very quick, and they enable you to get models off the ground. You can then iterate on your feature engineering to be more careful as time permits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding of Categorical Variables\n",
    "**One Hot Encoding (dummy variables, indicator variables)**\n",
    "Rule of thumb:\n",
    "* for any factor to be added (p -> p+1), there should be at least 10 observations for each (i.e. if you add two factos by including dummy variables, you should have 10x the number of variables, p, the data has after including the new variables)\n",
    "\n",
    "Ex.\n",
    "* n=100, p = 3\n",
    "> currently 33 1/3 observation per-factor<br>\n",
    "* if one p has 5 categories/levels -> n=100, p = 8 (assuming no base drop, which is wrong), no issue\n",
    "> each factor now has 100 / 8 observations<br>\n",
    "* if one p has 8 categories/levels -> n=100, p = 11 (assuming no base drop, which is wrong), there may be an issues\n",
    "> each factor now has 100 / 11 observations, even if the base case is dropped, this is still a potential issue\n",
    "\n",
    "Another rule of thumb:\n",
    "* There should be at least $\\sqrt{n}$ observations for any factor\n",
    "> this leads to an equivalent amount of observations for each factor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfitting\n",
    "* When we are able to build a model that performs well on data it has seen before, but does not predict well in new situations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
