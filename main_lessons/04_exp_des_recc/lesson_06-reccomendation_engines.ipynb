{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_2_sol(sol_dict):\n",
    "    a = True\n",
    "    b = False\n",
    "    c = \"We can't be sure.\"\n",
    "\n",
    "\n",
    "    pearson_dct = {\"If when x increases, y always increases, Pearson's correlation will be always be 1.\": b,\n",
    "                   \"If when x increases by 1, y always increases by 3, Pearson's correlation will always be 1.\": a,\n",
    "                   \"If when x increases by 1, y always decreases by 5, Pearson's correlation will always be -1.\": a,\n",
    "                   \"If when x increases by 1, y increases by 3 times x, Pearson's correlation will always be 1.\": b\n",
    "    }\n",
    "\n",
    "    if pearson_dct == sol_dict:\n",
    "        print(\"That's right!  Pearson's correlation relates to a linear relationship.  The second and third cases are examples of perfect linear relationships, where we would receive values of 1 and -1.  Only having an increase or decrease that are directly related will not lead to a Pearson's correlation coefficient of 1 or -1.  You can see this by testing out your function using the examples above without using assert statements.\")\n",
    "\n",
    "    else:\n",
    "        print(\"Oops!  That doesn't look right... Pearson's correlation relates to a linear relationship.  The second and third cases are examples of perfect linear relationships, where we would receive values of 1 and -1.  Only having an increase or decrease that are directly related will not lead to a Pearson's correlation coefficient of 1 or -1.  You can see this by testing out your function using the examples above without using assert statements.  Try looking at the correlation of different relationships to prove the values to yourself.\")\n",
    "\n",
    "\n",
    "def sim_4_sol(sol_dict):\n",
    "    a = True\n",
    "    b = False\n",
    "    c = \"We can't be sure.\"\n",
    "\n",
    "\n",
    "    spearman_dct = {\"If when x increases, y always increases, Spearman's correlation will be always be 1.\": a,\n",
    "                    \"If when x increases by 1, y always increases by 3, Spearman's correlation will always be 1.\": a,\n",
    "                    \"If when x increases by 1, y always decreases by 5, Spearman's correlation will always be -1.\": a,\n",
    "                    \"If when x increases by 1, y increases by 3 times x, Spearman's correlation will always be 1.\": a\n",
    "}\n",
    "    if spearman_dct == sol_dict:\n",
    "        print(\"That's right!  Unlike Pearson's correlation, Spearman's correlation can have perfect relationships (1 or -1 values) that aren't linear relationships.  You will notice that neither Spearman or Pearson correlation values suggest a relation when there are quadratic relationships.\")\n",
    "\n",
    "    else:\n",
    "        print(\"Oops!  That doesn't look right...these are actually all true statements! Unlike Pearson's correlation, Spearman's correlation can have perfect relationships (1 or -1 values) that aren't linear relationships.  You will notice that neither Spearman or Pearson correlation values suggest a relation when there are quadratic relationships.\")\n",
    "        \n",
    "def sim_6_sol(sol_dict):\n",
    "    a = True\n",
    "    b = False\n",
    "    c = \"We can't be sure.\"\n",
    "\n",
    "\n",
    "    corr_comp_dct = {\"For all columns of play_data, Spearman and Kendall's measures match.\": a,\n",
    "                    \"For all columns of play_data, Spearman and Pearson's measures match.\": b,\n",
    "                    \"For all columns of play_data, Pearson and Kendall's measures match.\": b}\n",
    "\n",
    "    if corr_comp_dct == sol_dict:\n",
    "        print(\"That's right!  Pearson does not match the other two measures, as it looks specifically for linear relationships.  However, Spearman and Kenall's measures are exactly the same to one another in the cases related to play_data.\")\n",
    "\n",
    "    else:\n",
    "        print(\"Oops!  That doesn't look right...Pearson does not match the other two measures, as it looks specifically for linear relationships.  However, Spearman and Kenall's measures are exactly the same to one another in the cases related to play_data.\")\n",
    "\n",
    "def test_eucl(x, y):\n",
    "    return np.linalg.norm(x - y)\n",
    "    \n",
    "\n",
    "def test_manhat(x,y):\n",
    "    return sum(abs(e - s) for s,e in zip(x, y))\n",
    "\n",
    "\n",
    "def test_recs(sol_dict):\n",
    "    sol_dict1 = {\n",
    "        'The type of recommendation system implemented here was a ...': 'user based collaborative filtering',\n",
    "        'The two methods used to estimate user similarity were: ': \"euclidean distance and pearson's correlation coefficient\",\n",
    "        'There was an issue with using the correlation coefficient.  What was it?': 'the spread in some ratings was zero'\n",
    "    }\n",
    "    if sol_dict1 == sol_dict:\n",
    "        return \"That's right! All of your solutions look good!\"\n",
    "    else:\n",
    "        for k, v in sol_dict.items():\n",
    "            if sol_dict1[k] != sol_dict[k]:\n",
    "                print(\"Oops! Your answer to: {} doesn't look quite right.\".format(k))\n",
    "\n",
    "def test_recs2(sol_dict2):\n",
    "    a = 567\n",
    "    b = 1503\n",
    "    c = 1319\n",
    "    d = 1325\n",
    "    e = 2526710\n",
    "    f = 0\n",
    "    g = 'Use another method to make recommendations - content based, knowledge based, or model based collaborative filtering'\n",
    "\n",
    "    sol_dict1 = {\n",
    "        'For how many pairs of users were we not able to obtain a measure of similarity using correlation?': e,\n",
    "        'For how many pairs of users were we not able to obtain a measure of similarity using euclidean distance?': f,\n",
    "        'For how many users were we unable to make any recommendations for using collaborative filtering?': c,\n",
    "        'For how many users were we unable to make 10 recommendations for using collaborative filtering?': d,\n",
    "        'What might be a way for us to get 10 recommendations for every user?': g\n",
    "    }\n",
    "    if sol_dict1 == sol_dict2:\n",
    "        return \"That's right! All of your solutions look good!\"\n",
    "    else:\n",
    "        for k, v in sol_dict2.items():\n",
    "            if sol_dict1[k] != sol_dict[k]:\n",
    "                print(\"Oops! Your answer to: {} doesn't look quite right.\".format(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation Engines\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Recommendations are being used to recommend everything from movies to music to friends to new destinations. There are three main methods for implementing recommendations that you will become familiar with throughout this lesson:\n",
    "* Knowledge Based Recommendations\n",
    "* Collaborative Filtering Based Recommendations\n",
    "* Content Based Recommendations\n",
    "\n",
    "After completing this lesson, you will be ready for the upcoming lessons where you will:\n",
    "* Learn about more advanced techniques.\n",
    "* Deploy your recommendations in a web application.\n",
    "\n",
    "These three lessons will aim to be extremely practical. The lessons will require that you write code to implement a number of different recommendation techniques.\n",
    "\n",
    "**Example Recommendations:**\n",
    "\n",
    "* LinkedIn and Facebook\n",
    "> Both LinkedIn and Facebook have recommendations for connections (business of friends) similar to what is shown below.\n",
    "\n",
    "* AirBnB Experiences and Destinations\n",
    "> AirBnB uses recommendations to determine experiences and destinations for their users.\n",
    "\n",
    "* Walmart, Amazon, and Other Retailers\n",
    "> As humans on the Internet, we all get pinged with constant recommendations from retailers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's Ahead\n",
    "\n",
    "### Types of Recommendations\n",
    "\n",
    "In this lesson, you will be working with the MovieTweetings data to apply each of the three methods of recommendations:\n",
    "1. Knowledge Based Recommendations\n",
    "2. Collaborative Filtering Based Recommendations\n",
    "3. Content Based Recommendations\n",
    "\n",
    "Within Collaborative Filtering, there are two main branches:\n",
    "1. Model Based Collaborative Filtering\n",
    "2. Neighborhood Based Collaborative Filtering\n",
    "\n",
    "In this lesson, you will implement Neighborhood Based Collaborative Filtering. In the next lesson, you will implement Model Based Collaborative Filtering.\n",
    "\n",
    "### Similarity Metrics\n",
    "\n",
    "In order to implement Neighborhood Based Collaborative Filtering, you will learn about some common ways to measure the similarity between two users (or two items) including:\n",
    "1. Pearson's correlation coefficient\n",
    "2. Spearman's correlation coefficient\n",
    "3. Kendall's Tau\n",
    "4. Euclidean Distance\n",
    "5. Manhattan Distance\n",
    "\n",
    "You will learn why sometimes one metric works better than another by looking at a specific situation where one metric provides more information than another.\n",
    "\n",
    "### Business Cases For Recommendations\n",
    "\n",
    "Finally, you will look at the four ideas needed for businesses to implement successful recommendations to drive revenue, which include:\n",
    "1. Relevance\n",
    "2. Novelty\n",
    "3. Serendipity\n",
    "4. Increased Diversity\n",
    "\n",
    "At the end of this lesson, you will have gained a ton of skills to build upon or to start creating your own recommendations in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Data - MovieTweetings\n",
    "\n",
    "If you would like additional information about the MovieTweetings data, you can find more information at the links provided here:\n",
    "* [The MovieTweetings white paper(DEADLINK)](http://crowdrec2013.noahlab.com.hk/papers/crowdrec2013_Dooms.pdf)\n",
    "* [A Github account set up for MovieTweetings](https://github.com/sidooms/MovieTweetings)\n",
    "* [A slide deck by Simon Doom about MovieTweetings.](https://www.slideshare.net/simondooms/movie-tweetings-a-movie-rating-dataset-collected-from-twitter)\n",
    "> Attached in repo as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Recommendations with MovieTweetings: Getting to Know The Data\n",
    "\n",
    "Throughout this lesson, you will be working with the [MovieTweetings Data](https://github.com/sidooms/MovieTweetings/tree/master/recsyschallenge2014).\n",
    "\n",
    "**Note:** There are solutions to each of the notebooks available by hitting the orange jupyter logo in the top left of this notebook.  Additionally, you can watch me work through the solutions on the screencasts that follow each workbook. \n",
    "\n",
    "To get started, read in the libraries and the two datasets you will be using throughout the lesson using the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import tests as t\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the MovieTweetings dataset originally taken from https://github.com/sidooms/MovieTweetings/tree/master/latest\n",
    "movies = pd.read_csv(\n",
    "    '06_recommendation_engines/movies.dat',\n",
    "    delimiter='::',\n",
    "    header=None,\n",
    "    names=['movie_id', 'movie', 'genre'],\n",
    "    dtype={'movie_id': object},\n",
    "    engine='python')\n",
    "reviews = pd.read_csv(\n",
    "    '06_recommendation_engines/ratings.dat',\n",
    "    delimiter='::',\n",
    "    header=None,\n",
    "    names=['user_id', 'movie_id', 'rating', 'timestamp'],\n",
    "    dtype={'movie_id': object, 'user_id': object, 'timestamp': object},\n",
    "    engine='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Take a Look At The Data \n",
    "\n",
    "Take a look at the data and use your findings to fill in the dictionary below with the correct responses to show your understanding of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35479, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000008</td>\n",
       "      <td>Edison Kinetoscopic Record of a Sneeze (1894)</td>\n",
       "      <td>Documentary|Short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000010</td>\n",
       "      <td>La sortie des usines Lumière (1895)</td>\n",
       "      <td>Documentary|Short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000012</td>\n",
       "      <td>The Arrival of a Train (1896)</td>\n",
       "      <td>Documentary|Short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>The Oxford and Cambridge University Boat Race ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000091</td>\n",
       "      <td>Le manoir du diable (1896)</td>\n",
       "      <td>Short|Horror</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  movie_id                                              movie  \\\n",
       "0  0000008      Edison Kinetoscopic Record of a Sneeze (1894)   \n",
       "1  0000010                La sortie des usines Lumière (1895)   \n",
       "2  0000012                      The Arrival of a Train (1896)   \n",
       "3       25  The Oxford and Cambridge University Boat Race ...   \n",
       "4  0000091                         Le manoir du diable (1896)   \n",
       "\n",
       "               genre  \n",
       "0  Documentary|Short  \n",
       "1  Documentary|Short  \n",
       "2  Documentary|Short  \n",
       "3                NaN  \n",
       "4       Short|Horror  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(movies.shape)\n",
    "display(movies.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(863866, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0114508</td>\n",
       "      <td>8</td>\n",
       "      <td>1381006850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0208092</td>\n",
       "      <td>5</td>\n",
       "      <td>1586466072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0358273</td>\n",
       "      <td>9</td>\n",
       "      <td>1579057827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>10039344</td>\n",
       "      <td>5</td>\n",
       "      <td>1578603053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>6751668</td>\n",
       "      <td>9</td>\n",
       "      <td>1578955697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id  movie_id  rating   timestamp\n",
       "0       1   0114508       8  1381006850\n",
       "1       2   0208092       5  1586466072\n",
       "2       2   0358273       9  1579057827\n",
       "3       2  10039344       5  1578603053\n",
       "4       2   6751668       9  1578955697"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(reviews.shape)\n",
    "display(reviews.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_sol1 = {\n",
    "'The number of movies in the dataset': movies['movie'].nunique()\n",
    ",'The number of ratings in the dataset': reviews['rating'].notnull().sum()\n",
    ",'The number of different genres': movies['genre'].nunique()\n",
    ",'The number of unique users in the dataset': reviews['user_id'].nunique()\n",
    ",'The number missing ratings in the reviews dataset': reviews['rating'].isna().sum()\n",
    ",'The average rating given across all ratings': reviews['rating'].mean()\n",
    ",'The minimum rating given across all ratings': reviews['rating'].min()\n",
    ",'The maximum rating given across all ratings': reviews['rating'].max()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'The number of movies in the dataset': 35416,\n",
       " 'The number of ratings in the dataset': 863866,\n",
       " 'The number of different genres': 2736,\n",
       " 'The number of unique users in the dataset': 67353,\n",
       " 'The number missing ratings in the reviews dataset': 0,\n",
       " 'The average rating given across all ratings': 7.315877693994207,\n",
       " 'The minimum rating given across all ratings': 0,\n",
       " 'The maximum rating given across all ratings': 10}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_sol1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Data Cleaning\n",
    "\n",
    "Next, we need to pull some additional relevant information out of the existing columns. \n",
    "\n",
    "For each of the datasets, there are a couple of cleaning steps we need to take care of:\n",
    "\n",
    "#### Movies\n",
    "* Pull the date from the title and create new column\n",
    "* Dummy the date column with 1's and 0's for each century of a movie (1800's, 1900's, and 2000's)\n",
    "* Dummy column the genre with 1's and 0's\n",
    "\n",
    "#### Reviews\n",
    "* Create a date out of time stamp\n",
    "\n",
    "You can check your results against the header of my solution by running the cell below with the **show_clean_dataframes** function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_year_in_paren(s):\n",
    "    close_left = s.rfind('(')\n",
    "    close_right = s.rfind(')')\n",
    "    s_paren = s[close_left+1:close_right]\n",
    "\n",
    "    return s_paren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie</th>\n",
       "      <th>genre</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000008</td>\n",
       "      <td>Edison Kinetoscopic Record of a Sneeze (1894)</td>\n",
       "      <td>Documentary|Short</td>\n",
       "      <td>1894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000010</td>\n",
       "      <td>La sortie des usines Lumière (1895)</td>\n",
       "      <td>Documentary|Short</td>\n",
       "      <td>1895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000012</td>\n",
       "      <td>The Arrival of a Train (1896)</td>\n",
       "      <td>Documentary|Short</td>\n",
       "      <td>1896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>The Oxford and Cambridge University Boat Race ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000091</td>\n",
       "      <td>Le manoir du diable (1896)</td>\n",
       "      <td>Short|Horror</td>\n",
       "      <td>1896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  movie_id                                              movie  \\\n",
       "0  0000008      Edison Kinetoscopic Record of a Sneeze (1894)   \n",
       "1  0000010                La sortie des usines Lumière (1895)   \n",
       "2  0000012                      The Arrival of a Train (1896)   \n",
       "3       25  The Oxford and Cambridge University Boat Race ...   \n",
       "4  0000091                         Le manoir du diable (1896)   \n",
       "\n",
       "               genre  date  \n",
       "0  Documentary|Short  1894  \n",
       "1  Documentary|Short  1895  \n",
       "2  Documentary|Short  1896  \n",
       "3                NaN  1895  \n",
       "4       Short|Horror  1896  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies['date'] = movies['movie'].apply(lambda x: remove_year_in_paren(x))\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie</th>\n",
       "      <th>genre</th>\n",
       "      <th>date</th>\n",
       "      <th>1800's</th>\n",
       "      <th>1900's</th>\n",
       "      <th>2000's</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000008</td>\n",
       "      <td>Edison Kinetoscopic Record of a Sneeze (1894)</td>\n",
       "      <td>Documentary|Short</td>\n",
       "      <td>1894</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000010</td>\n",
       "      <td>La sortie des usines Lumière (1895)</td>\n",
       "      <td>Documentary|Short</td>\n",
       "      <td>1895</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000012</td>\n",
       "      <td>The Arrival of a Train (1896)</td>\n",
       "      <td>Documentary|Short</td>\n",
       "      <td>1896</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>The Oxford and Cambridge University Boat Race ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1895</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000091</td>\n",
       "      <td>Le manoir du diable (1896)</td>\n",
       "      <td>Short|Horror</td>\n",
       "      <td>1896</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  movie_id                                              movie  \\\n",
       "0  0000008      Edison Kinetoscopic Record of a Sneeze (1894)   \n",
       "1  0000010                La sortie des usines Lumière (1895)   \n",
       "2  0000012                      The Arrival of a Train (1896)   \n",
       "3       25  The Oxford and Cambridge University Boat Race ...   \n",
       "4  0000091                         Le manoir du diable (1896)   \n",
       "\n",
       "               genre  date  1800's  1900's  2000's  \n",
       "0  Documentary|Short  1894       1       0       0  \n",
       "1  Documentary|Short  1895       1       0       0  \n",
       "2  Documentary|Short  1896       1       0       0  \n",
       "3                NaN  1895       1       0       0  \n",
       "4       Short|Horror  1896       1       0       0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_ind = {'18':\"1800's\",'19':\"1900's\",'20':\"2000's\"}\n",
    "for date in date_ind:\n",
    "    movies.loc[:,date_ind[date]] = 0\n",
    "    movies.loc[movies['date'].str[:2] == date, date_ind[date]] = 1\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie</th>\n",
       "      <th>genre</th>\n",
       "      <th>date</th>\n",
       "      <th>1800's</th>\n",
       "      <th>1900's</th>\n",
       "      <th>2000's</th>\n",
       "      <th>Western</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>War</th>\n",
       "      <th>...</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Family</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Game-Show</th>\n",
       "      <th>Fantasy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000008</td>\n",
       "      <td>Edison Kinetoscopic Record of a Sneeze (1894)</td>\n",
       "      <td>Documentary|Short</td>\n",
       "      <td>1894</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000010</td>\n",
       "      <td>La sortie des usines Lumière (1895)</td>\n",
       "      <td>Documentary|Short</td>\n",
       "      <td>1895</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000012</td>\n",
       "      <td>The Arrival of a Train (1896)</td>\n",
       "      <td>Documentary|Short</td>\n",
       "      <td>1896</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>The Oxford and Cambridge University Boat Race ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1895</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000091</td>\n",
       "      <td>Le manoir du diable (1896)</td>\n",
       "      <td>Short|Horror</td>\n",
       "      <td>1896</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  movie_id                                              movie  \\\n",
       "0  0000008      Edison Kinetoscopic Record of a Sneeze (1894)   \n",
       "1  0000010                La sortie des usines Lumière (1895)   \n",
       "2  0000012                      The Arrival of a Train (1896)   \n",
       "3       25  The Oxford and Cambridge University Boat Race ...   \n",
       "4  0000091                         Le manoir du diable (1896)   \n",
       "\n",
       "               genre  date  1800's  1900's  2000's  Western  Mystery  War  \\\n",
       "0  Documentary|Short  1894       1       0       0        0        0    0   \n",
       "1  Documentary|Short  1895       1       0       0        0        0    0   \n",
       "2  Documentary|Short  1896       1       0       0        0        0    0   \n",
       "3                NaN  1895       1       0       0        0        0    0   \n",
       "4       Short|Horror  1896       1       0       0        0        0    0   \n",
       "\n",
       "   ...  Drama  Romance  Documentary  Animation  Horror  Comedy  Family  Crime  \\\n",
       "0  ...      0        0            1          0       0       0       0      0   \n",
       "1  ...      0        0            1          0       0       0       0      0   \n",
       "2  ...      0        0            1          0       0       0       0      0   \n",
       "3  ...      0        0            0          0       0       0       0      0   \n",
       "4  ...      0        0            0          0       1       0       0      0   \n",
       "\n",
       "   Game-Show  Fantasy  \n",
       "0          0        0  \n",
       "1          0        0  \n",
       "2          0        0  \n",
       "3          0        0  \n",
       "4          0        0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of different genres\n",
    "genres = []\n",
    "for val in movies.genre:\n",
    "    try:\n",
    "        genres.extend(val.split('|'))\n",
    "    except AttributeError:\n",
    "        pass\n",
    "genres = set(genres)\n",
    "\n",
    "def split_genres(val):\n",
    "    try:\n",
    "        if val.find(gene) >-1:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    except AttributeError:\n",
    "        return 0\n",
    "\n",
    "# Apply function for each genre\n",
    "for gene in genres:        \n",
    "    movies[gene] = movies['genre'].apply(split_genres)\n",
    "# print(\"The number of genres is {}.\".format(len(genres)))\n",
    "\n",
    "# movies = pd.concat([movies,pd.get_dummies(movies['genre'])],axis=1)\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0114508</td>\n",
       "      <td>8</td>\n",
       "      <td>1381006850</td>\n",
       "      <td>2013-10-05 21:00:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0208092</td>\n",
       "      <td>5</td>\n",
       "      <td>1586466072</td>\n",
       "      <td>2020-04-09 21:01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0358273</td>\n",
       "      <td>9</td>\n",
       "      <td>1579057827</td>\n",
       "      <td>2020-01-15 03:10:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>10039344</td>\n",
       "      <td>5</td>\n",
       "      <td>1578603053</td>\n",
       "      <td>2020-01-09 20:50:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>6751668</td>\n",
       "      <td>9</td>\n",
       "      <td>1578955697</td>\n",
       "      <td>2020-01-13 22:48:17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id  movie_id  rating   timestamp                date\n",
       "0       1   0114508       8  1381006850 2013-10-05 21:00:50\n",
       "1       2   0208092       5  1586466072 2020-04-09 21:01:12\n",
       "2       2   0358273       9  1579057827 2020-01-15 03:10:27\n",
       "3       2  10039344       5  1578603053 2020-01-09 20:50:53\n",
       "4       2   6751668       9  1578955697 2020-01-13 22:48:17"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['date'] = pd.to_datetime(reviews['timestamp'],unit='s')\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "The solution to the previous notebook is available in two videos below. Remember you can access the solution notebooks from within the classroom workspaces by clicking on the orange, Jupyter Notebook icon in the upper left hand corner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 1 - Knowledge Based Recommendations\n",
    "\n",
    "A knowledge based recommendation is one in which knowledge about the item or user preferences are used to make a recommendation.\n",
    "\n",
    "Knowledge based recommendations are pretty common when purchasing luxury items. Take a look at the filters available on Zillow in the image below. This is an example of building in a knowledge based recommendation, as users can add their own preferences to the items that are provided.\n",
    "\n",
    "<center><img src=\"rec_02.png\" width=500></center>\n",
    "\n",
    "* **Rank Based Recommendations:** Recommendations based on highest ratings, most purchases, most listened to, etc.\n",
    "> Based on frequency independent of condition\n",
    "\n",
    "* **Knowledge Based Recommendations:** Knowledge about the item or user preferences are used to make a recommendation\n",
    "\n",
    "<center><img src=\"rec_01.png\" width=500></center>\n",
    "\n",
    "Often a rank based algorithm is provided along with knowledge based recommendations to bring the most popular items in particular categories to the user's attention.\n",
    "\n",
    "In the next concept, you will get some practice implementing this type of recommendation for the MovieTweetings dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - Recommendation with MovieTweetings: Most Popular Recommendation\n",
    "\n",
    "Now that you have created the necessary columns we will be using throughout the rest of the lesson on creating recommendations, let's get started with the first of our recommendations.\n",
    "\n",
    "To get started, read in the libraries and the two datasets you will be using throughout the lesson using the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import .rec_tests as t\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Read in the datasets\n",
    "movies = pd.read_csv('06_recommendation_engines/movies_clean.csv')\n",
    "reviews = pd.read_csv('06_recommendation_engines/reviews_clean.csv')\n",
    "del movies['Unnamed: 0']\n",
    "del reviews['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. How To Find The Most Popular Movies\n",
    "\n",
    "For this notebook, we have a single task.  The task is that no matter the user, we need to provide a list of the recommendations based on simply the most popular items.\n",
    "\n",
    "For this task, we will consider what is \"most popular\" based on the following criteria:\n",
    "\n",
    "* A movie with the highest average rating is considered best\n",
    "* With ties, movies that have more ratings are better\n",
    "* A movie must have a minimum of 5 ratings to be considered among the best movies\n",
    "* If movies are tied in their average rating and number of ratings, the ranking is determined by the movie that is the most recent rating\n",
    "\n",
    "With these criteria, the goal for this notebook is to take a `user_id` and provide back the `n_top` recommendations.  Use the function below as the scaffolding that will be used for all the future recommendations as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>date</th>\n",
       "      <th>month_1</th>\n",
       "      <th>month_2</th>\n",
       "      <th>month_3</th>\n",
       "      <th>month_4</th>\n",
       "      <th>month_5</th>\n",
       "      <th>...</th>\n",
       "      <th>month_9</th>\n",
       "      <th>month_10</th>\n",
       "      <th>month_11</th>\n",
       "      <th>month_12</th>\n",
       "      <th>year_2013</th>\n",
       "      <th>year_2014</th>\n",
       "      <th>year_2015</th>\n",
       "      <th>year_2016</th>\n",
       "      <th>year_2017</th>\n",
       "      <th>year_2018</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>68646</td>\n",
       "      <td>10</td>\n",
       "      <td>1381620027</td>\n",
       "      <td>2013-10-12 23:20:27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>113277</td>\n",
       "      <td>10</td>\n",
       "      <td>1379466669</td>\n",
       "      <td>2013-09-18 01:11:09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>422720</td>\n",
       "      <td>8</td>\n",
       "      <td>1412178746</td>\n",
       "      <td>2014-10-01 15:52:26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>454876</td>\n",
       "      <td>8</td>\n",
       "      <td>1394818630</td>\n",
       "      <td>2014-03-14 17:37:10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>790636</td>\n",
       "      <td>7</td>\n",
       "      <td>1389963947</td>\n",
       "      <td>2014-01-17 13:05:47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating   timestamp                 date  month_1  \\\n",
       "0        1     68646      10  1381620027  2013-10-12 23:20:27        0   \n",
       "1        1    113277      10  1379466669  2013-09-18 01:11:09        0   \n",
       "2        2    422720       8  1412178746  2014-10-01 15:52:26        0   \n",
       "3        2    454876       8  1394818630  2014-03-14 17:37:10        0   \n",
       "4        2    790636       7  1389963947  2014-01-17 13:05:47        0   \n",
       "\n",
       "   month_2  month_3  month_4  month_5  ...  month_9  month_10  month_11  \\\n",
       "0        0        0        0        0  ...        0         1         0   \n",
       "1        0        0        0        0  ...        0         0         0   \n",
       "2        0        0        0        0  ...        0         1         0   \n",
       "3        0        0        0        0  ...        0         0         0   \n",
       "4        0        0        0        0  ...        0         0         0   \n",
       "\n",
       "   month_12  year_2013  year_2014  year_2015  year_2016  year_2017  year_2018  \n",
       "0         0          1          0          0          0          0          0  \n",
       "1         0          1          0          0          0          0          0  \n",
       "2         0          0          1          0          0          0          0  \n",
       "3         0          0          1          0          0          0          0  \n",
       "4         0          0          1          0          0          0          0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ranked_df(movies, reviews):\n",
    "        '''\n",
    "        INPUT\n",
    "        movies - the movies dataframe\n",
    "        reviews - the reviews dataframe\n",
    "        \n",
    "        OUTPUT\n",
    "        ranked_movies - a dataframe with movies that are sorted by highest avg rating, more reviews, \n",
    "                        then time, and must have more than 4 ratings\n",
    "        '''\n",
    "        \n",
    "        # Pull the average ratings and number of ratings for each movie\n",
    "        movie_ratings = reviews.groupby('movie_id')['rating']\n",
    "        avg_ratings = movie_ratings.mean()\n",
    "        num_ratings = movie_ratings.count()\n",
    "        last_rating = pd.DataFrame(reviews.groupby('movie_id').max()['date'])\n",
    "        last_rating.columns = ['last_rating']\n",
    "\n",
    "        # Add Dates\n",
    "        rating_count_df = pd.DataFrame({'avg_rating': avg_ratings, 'num_ratings': num_ratings})\n",
    "        rating_count_df = rating_count_df.join(last_rating)\n",
    "\n",
    "        # merge with the movies dataset\n",
    "        movie_recs = movies.set_index('movie_id').join(rating_count_df)\n",
    "\n",
    "        # sort by top avg rating and number of ratings\n",
    "        ranked_movies = movie_recs.sort_values(['avg_rating', 'num_ratings', 'last_rating'], ascending=False)\n",
    "\n",
    "        # for edge cases - subset the movie list to those with only 5 or more reviews\n",
    "        ranked_movies = ranked_movies[ranked_movies['num_ratings'] > 4]\n",
    "        \n",
    "        return ranked_movies\n",
    "\n",
    "    \n",
    "def popular_recommendations(user_id, n_top, ranked_movies):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - the user_id (str) of the individual you are making recommendations for\n",
    "    n_top - an integer of the number recommendations you want back\n",
    "    ranked_movies - a pandas dataframe of the already ranked movies based on avg rating, count, and time\n",
    "\n",
    "    OUTPUT:\n",
    "    top_movies - a list of the n_top recommended movies by movie title in order best to worst\n",
    "    '''\n",
    "\n",
    "    top_movies = list(ranked_movies['movie'][:n_top])\n",
    "\n",
    "    return top_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the three criteria above, you should be able to put together the above function.  If you feel confident in your solution, check the results of your function against our solution. On the next page, you can see a walkthrough and you can of course get the solution by looking at the solution notebook available in this workspace.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 20 movies recommended for id 1\n",
    "ranked_movies = create_ranked_df(movies, reviews) # only run this once - it is not fast\n",
    "\n",
    "recs_20_for_1 = popular_recommendations('1', 20, ranked_movies)\n",
    "\n",
    "# Top 5 movies recommended for id 53968\n",
    "recs_5_for_53968 = popular_recommendations('53968', 5, ranked_movies)\n",
    "\n",
    "# Top 100 movies recommended for id 70000\n",
    "recs_100_for_70000 = popular_recommendations('70000', 100, ranked_movies)\n",
    "\n",
    "# Top 35 movies recommended for id 43\n",
    "recs_35_for_43 = popular_recommendations('43', 35, ranked_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notice:** This wasn't the only way we could have determined the \"top rated\" movies.  You can imagine that in keeping track of trending news or trending social events, you would likely want to create a time window from the current time, and then pull the articles in the most recent time frame.  There are always going to be some subjective decisions to be made.  \n",
    "\n",
    "If you find that no one is paying any attention to your most popular recommendations, then it might be time to find a new way to recommend, which is what the next parts of the lesson should prepare us to do!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part II: Adding Filters\n",
    "\n",
    "Now that you have created a function to give back the **n_top** movies, let's make it a bit more robust.  Add arguments that will act as filters for the movie **year** and **genre**.  \n",
    "\n",
    "Use the cells below to adjust your existing function to allow for **year** and **genre** arguments as **lists** of **strings**.  Then your ending results are filtered to only movies within the lists of provided years and genres (as `or` conditions).  If no list is provided, there should be no filter applied.\n",
    "\n",
    "You can adjust other necessary inputs as necessary to retrieve the final results you are looking for!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def popular_recs_filtered(user_id, n_top, ranked_movies, years=None, genres=None):\n",
    "    '''\n",
    "    REDO THIS DOC STRING\n",
    "    \n",
    "    INPUT:\n",
    "    user_id - the user_id (str) of the individual you are making recommendations for\n",
    "    n_top - an integer of the number recommendations you want back\n",
    "    ranked_movies - a pandas dataframe of the already ranked movies based on avg rating, count, and time\n",
    "    years - a list of strings with years of movies\n",
    "    genres - a list of strings with genres of movies\n",
    "    \n",
    "    OUTPUT:\n",
    "    top_movies - a list of the n_top recommended movies by movie title in order best to worst\n",
    "    '''\n",
    "    # Filter movies based on year and genre\n",
    "    if years is not None:\n",
    "        ranked_movies = ranked_movies[ranked_movies['date'].isin(years)]\n",
    "\n",
    "    if genres is not None:\n",
    "        num_genre_match = ranked_movies[genres].sum(axis=1)\n",
    "        ranked_movies = ranked_movies.loc[num_genre_match > 0, :]\n",
    "            \n",
    "            \n",
    "    # create top movies list \n",
    "    top_movies = list(ranked_movies['movie'][:n_top])\n",
    "\n",
    "    return top_movies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 20 movies recommended for id 1 with years=['2015', '2016', '2017', '2018'], genres=['History']\n",
    "recs_20_for_1_filtered = popular_recs_filtered('1', 20, ranked_movies, years=['2015', '2016', '2017', '2018'], genres=['History'])\n",
    "\n",
    "# Top 5 movies recommended for id 53968 with no genre filter but years=['2015', '2016', '2017', '2018']\n",
    "recs_5_for_53968_filtered = popular_recs_filtered('53968', 5, ranked_movies, years=['2015', '2016', '2017', '2018'])\n",
    "\n",
    "# Top 100 movies recommended for id 70000 with no year filter but genres=['History', 'News']\n",
    "recs_100_for_70000_filtered = popular_recs_filtered('70000', 100, ranked_movies, genres=['History', 'News'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 2 - More Personalized Recommendations\n",
    "\n",
    "In some cases, we need to be able to send recommendations without a user telling us exactly what they want or in a more personalized way than simply the top items. Imagine you want to send an email of recommendations or place recommendations within a web page (the side of a blog or as a banner advertisement); in these cases, it is often useful to implement information that we know about users or items to make these recommendations. This leads to some additional recommendation methods!\n",
    "\n",
    "#### Collaborative Filtering & Content Based Recommendations\n",
    "\n",
    "* **Collaborative Filtering:** A method of making recommendations based on using the collaboration of user-item interactions\n",
    "\n",
    "<center><img src='rec_03.png' width=500></center>\n",
    "\n",
    "* **Content Based Recommendations:** are when we use information about the users or items to assist in our recommendations\n",
    "\n",
    "<center><img src='rec_04.png' width=500></center>\n",
    "\n",
    "* **Example of Data for Collaborative Filtering:**\n",
    "* Item ratings for each user\n",
    "* Item liked by user or not\n",
    "* Item used by user or not\n",
    "\n",
    "<center><img src='rec_05.png' width=500></center>\n",
    "\n",
    "> * When a user is inputting her/his information (location input), this is an example of knowledge based recommending\n",
    "> * When we use connections between users and items (connecting Mike and Pradeep as similar), this is an example of collaborative filtering\n",
    "> * When we use information about the items or users to recommend new items (items related to robotics), this is an example of content based recommending.\n",
    "\n",
    "#### Collaborative Filtering Methods\n",
    "\n",
    "1. Model Based\n",
    "2. Neighborhood Based\n",
    "> used to identify items or users that are \"neighbors\" with one another\n",
    "\n",
    "<center><img src='rec_06.png' width=500></center>\n",
    "\n",
    "There are a number of ways we might go about finding an individual's closest neighbors - the metrics we will take a closer look at include:\n",
    "1. Pearson's correlation coefficient\n",
    "2. Spearman's correlation coefficient\n",
    "3. Kendall's Tau\n",
    "4. Euclidean Distance\n",
    "5. Manhattan Distance\n",
    "\n",
    "<center><img src='rec_07.png' width=500></center>\n",
    "\n",
    "<center><img src='rec_08.png' width=500></center>\n",
    "\n",
    "In the next cells, you will work through a few examples to get more familiar with how each of these metrics is computed, and why you might use one over another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3 - How to Find Your Neighbor?\n",
    "\n",
    "In neighborhood based collaborative filtering, it is incredibly important to be able to identify an individual's neighbors. Let's look at a small dataset in order to understand how we can use different metrics to identify close neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr, kendalltau\n",
    "import matplotlib.pyplot as plt\n",
    "# import tests as t\n",
    "# import helper as h\n",
    "%matplotlib inline\n",
    "\n",
    "play_data = pd.DataFrame({'x1': [-3, -2, -1, 0, 1, 2, 3], \n",
    "               'x2': [9, 4, 1, 0, 1, 4, 9],\n",
    "               'x3': [1, 2, 3, 4, 5, 6, 7],\n",
    "               'x4': [2, 5, 15, 27, 28, 30, 31]\n",
    "})\n",
    "\n",
    "#create play data dataframe\n",
    "play_data = play_data[['x1', 'x2', 'x3', 'x4']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measures of Similarity\n",
    "\n",
    "The first metrics we will look at have similar characteristics:\n",
    "\n",
    "1. Pearson's Correlation Coefficient\n",
    "2. Spearman's Correlation Coefficient\n",
    "3. Kendall's Tau\n",
    "\n",
    "Let's take a look at each of these individually.\n",
    "\n",
    "### Pearson's Correlation\n",
    "\n",
    "First, **Pearson's correlation coefficient** is a measure related to the strength and direction of a **linear** relationship.  \n",
    "\n",
    "If we have two vectors x and y, we can compare their individual elements in the following way to calculate Pearson's correlation coefficient:\n",
    "\n",
    "\n",
    "$$CORR(\\textbf{x}, \\textbf{y}) = \\frac{\\sum\\limits_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum\\limits_{i=1}^{n}(x_i-\\bar{x})^2}\\sqrt{\\sum\\limits_{i=1}^{n}(y_i-\\bar{y})^2}} $$\n",
    "\n",
    "where \n",
    "\n",
    "$$\\bar{x} = \\frac{1}{n}\\sum\\limits_{i=1}^{n}x_i$$\n",
    "\n",
    "##### 1. Write a function that takes in two vectors and returns the Pearson correlation coefficient.  You can then compare your answer to the built in function in NumPy by using the assert statements in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_corr(x, y):\n",
    "    '''\n",
    "    INPUT\n",
    "    x - an array of matching length to array y\n",
    "    y - an array of matching length to array x\n",
    "    OUTPUT\n",
    "    corr - the pearson correlation coefficient for comparing x and y\n",
    "    '''\n",
    "    a = x - np.mean(x)\n",
    "    b = y - np.mean(y)\n",
    "    numerator = np.sum(a*b)\n",
    "    \n",
    "    c = np.sum(a**2)\n",
    "    c_1 = np.sqrt(c)\n",
    "    d = np.sum(b**2)\n",
    "    d_1 = np.sqrt(d)\n",
    "    denominator = c_1 * d_1\n",
    "    \n",
    "    corr = numerator / denominator\n",
    "                 \n",
    "    return corr            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If this is all you see, it looks like you are all set!  Nice job coding up Pearson's correlation coefficient!\n"
     ]
    }
   ],
   "source": [
    "assert pearson_corr(play_data['x1'], play_data['x2']) == np.corrcoef(play_data['x1'], play_data['x2'])[0][1], 'Oops!  The correlation between the first two columns should be 0, but your function returned {}.'.format(pearson_corr(play_data['x1'], play_data['x2']))\n",
    "assert round(pearson_corr(play_data['x1'], play_data['x3']), 2) == np.corrcoef(play_data['x1'], play_data['x3'])[0][1], 'Oops!  The correlation between the first and third columns should be {}, but your function returned {}.'.format(np.corrcoef(play_data['x1'], play_data['x3'])[0][1], pearson_corr(play_data['x1'], play_data['x3']))\n",
    "assert round(pearson_corr(play_data['x3'], play_data['x4']), 2) == round(np.corrcoef(play_data['x3'], play_data['x4'])[0][1], 2), 'Oops!  The correlation between the first and third columns should be {}, but your function returned {}.'.format(np.corrcoef(play_data['x3'], play_data['x4'])[0][1], pearson_corr(play_data['x3'], play_data['x4']))\n",
    "print(\"If this is all you see, it looks like you are all set!  Nice job coding up Pearson's correlation coefficient!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Now that you have computed **Pearson's correlation coefficient**, use the dictionary below to identify statements that are true about **this** measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's right!  Pearson's correlation relates to a linear relationship.  The second and third cases are examples of perfect linear relationships, where we would receive values of 1 and -1.  Only having an increase or decrease that are directly related will not lead to a Pearson's correlation coefficient of 1 or -1.  You can see this by testing out your function using the examples above without using assert statements.\n"
     ]
    }
   ],
   "source": [
    "a = True\n",
    "b = False\n",
    "c = \"We can't be sure.\"\n",
    "\n",
    "\n",
    "pearson_dct = {\"If when x increases, y always increases, Pearson's correlation will be always be 1.\": b,\n",
    "               \"If when x increases by 1, y always increases by 3, Pearson's correlation will always be 1.\": a,\n",
    "               \"If when x increases by 1, y always decreases by 5, Pearson's correlation will always be -1.\": a,\n",
    "               \"If when x increases by 1, y increases by 3 times x, Pearson's correlation will always be 1.\": b\n",
    "}\n",
    "\n",
    "sim_2_sol(pearson_dct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spearman's Correlation\n",
    "\n",
    "Now, let's look at **Spearman's correlation coefficient**. Spearman's correlation is what is known as a [non-parametric](https://en.wikipedia.org/wiki/Nonparametric_statistics) statistic, which is a statistic whose distribution doesn't depend on parameters. (Statistics that follow normal distributions or binomial distributions are examples of parametric statistics.)  \n",
    "\n",
    "Frequently non-parametric statistics are based on the ranks of data rather than the original values collected.  This happens to be the case with Spearman's correlation coefficient, which is calculated similarly to Pearson's correlation.  However, instead of using the raw data, we use the rank of each value.\n",
    "\n",
    "You can quickly change from the raw data to the ranks using the **.rank()** method as shown here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we map each of our data to ranked data values as shown above:\n",
    "\n",
    "$$\\textbf{x} \\rightarrow \\textbf{x}^{r}$$\n",
    "$$\\textbf{y} \\rightarrow \\textbf{y}^{r}$$\n",
    "\n",
    "Here, we let the **r** indicate these are ranked values (this is not raising any value to the power of r).  Then we compute Spearman's correlation coefficient as:\n",
    "\n",
    "$$SCORR(\\textbf{x}, \\textbf{y}) = \\frac{\\sum\\limits_{i=1}^{n}(x^{r}_i - \\bar{x}^{r})(y^{r}_i - \\bar{y}^{r})}{\\sqrt{\\sum\\limits_{i=1}^{n}(x^{r}_i-\\bar{x}^{r})^2}\\sqrt{\\sum\\limits_{i=1}^{n}(y^{r}_i-\\bar{y}^{r})^2}} $$\n",
    "\n",
    "where \n",
    "\n",
    "$$\\bar{x}^r = \\frac{1}{n}\\sum\\limits_{i=1}^{n}x^r_i$$\n",
    "\n",
    "##### 3. Write a function that takes in two vectors and returns the Spearman correlation coefficient.  You can then compare your answer to the built in function in scipy stats by using the assert statements in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ranked values for the variable x1 are: [1. 2. 3. 4. 5. 6. 7.]\n",
      "The raw data values for the variable x1 are: [-3 -2 -1  0  1  2  3]\n"
     ]
    }
   ],
   "source": [
    "print(\"The ranked values for the variable x1 are: {}\".format(np.array(play_data['x1'].rank())))\n",
    "print(\"The raw data values for the variable x1 are: {}\".format(np.array(play_data['x1'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_spearman(x, y):\n",
    "    '''\n",
    "    INPUT\n",
    "    x - an array of matching length to array y\n",
    "    y - an array of matching length to array x\n",
    "    OUTPUT\n",
    "    corr - the spearman correlation coefficient for comparing x and y\n",
    "    '''\n",
    "    x_r, y_r = x.rank(), y.rank()\n",
    "    \n",
    "    corr = pearson_corr(x=x_r,y=y_r)\n",
    "                    \n",
    "    return corr  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If this is all you see, it looks like you are all set!  Nice job coding up Spearman's correlation coefficient!\n"
     ]
    }
   ],
   "source": [
    "# This cell will test your function against the built in scipy function\n",
    "assert corr_spearman(play_data['x1'], play_data['x2']) == spearmanr(play_data['x1'], play_data['x2'])[0], 'Oops!  The correlation between the first two columns should be 0, but your function returned {}.'.format(compute_corr(play_data['x1'], play_data['x2']))\n",
    "assert round(corr_spearman(play_data['x1'], play_data['x3']), 2) == spearmanr(play_data['x1'], play_data['x3'])[0], 'Oops!  The correlation between the first and third columns should be {}, but your function returned {}.'.format(np.corrcoef(play_data['x1'], play_data['x3'])[0][1], compute_corr(play_data['x1'], play_data['x3']))\n",
    "assert round(corr_spearman(play_data['x3'], play_data['x4']), 2) == round(spearmanr(play_data['x3'], play_data['x4'])[0], 2), 'Oops!  The correlation between the first and third columns should be {}, but your function returned {}.'.format(np.corrcoef(play_data['x3'], play_data['x4'])[0][1], compute_corr(play_data['x3'], play_data['x4']))\n",
    "print(\"If this is all you see, it looks like you are all set!  Nice job coding up Spearman's correlation coefficient!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Now that you have computed **Spearman's correlation coefficient**, use the dictionary below to identify statements that are true about **this** measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's right!  Unlike Pearson's correlation, Spearman's correlation can have perfect relationships (1 or -1 values) that aren't linear relationships.  You will notice that neither Spearman or Pearson correlation values suggest a relation when there are quadratic relationships.\n"
     ]
    }
   ],
   "source": [
    "a = True\n",
    "b = False\n",
    "c = \"We can't be sure.\"\n",
    "\n",
    "\n",
    "spearman_dct = {\"If when x increases, y always increases, Spearman's correlation will be always be 1.\": a,\n",
    "               \"If when x increases by 1, y always increases by 3, Spearman's correlation will always be 1.\": a,\n",
    "               \"If when x increases by 1, y always decreases by 5, Spearman's correlation will always be -1.\": a,\n",
    "               \"If when x increases by 1, y increases by 3 times x, Spearman's correlation will always be 1.\": a\n",
    "}\n",
    "\n",
    "sim_4_sol(spearman_dct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kendall's Tau\n",
    "\n",
    "Kendall's tau is quite similar to Spearman's correlation coefficient.  Both of these measures are non-parametric measures of a relationship.  Specifically both Spearman and Kendall's coefficients are calculated based on ranking data and not the raw data.  \n",
    "\n",
    "Similar to both of the previous measures, Kendall's Tau is always between -1 and 1, where -1 suggests a strong, negative relationship between two variables and 1 suggests a strong, positive relationship between two variables.\n",
    "\n",
    "Though Spearman's and Kendall's measures are very similar, there are statistical advantages to choosing Kendall's measure in that Kendall's Tau has smaller variability when using larger sample sizes.  However Spearman's measure is more computationally efficient, as Kendall's Tau is O(n^2) and Spearman's correlation is O(nLog(n)). You can find more on this topic in [this thread](https://www.researchgate.net/post/Does_Spearmans_rho_have_any_advantage_over_Kendalls_tau).\n",
    "\n",
    "Let's take a closer look at exactly how this measure is calculated.  Again, we want to map our data to ranks:\n",
    "\n",
    "$$\\textbf{x} \\rightarrow \\textbf{x}^{r}$$\n",
    "$$\\textbf{y} \\rightarrow \\textbf{y}^{r}$$\n",
    "\n",
    "Then we calculate Kendall's Tau as:\n",
    "\n",
    "$$TAU(\\textbf{x}, \\textbf{y}) = \\frac{2}{n(n -1)}\\sum_{i < j}sgn(x^r_i - x^r_j)sgn(y^r_i - y^r_j)$$\n",
    "\n",
    "Where $sgn$ takes the the sign associated with the difference in the ranked values.  An alternative way to write \n",
    "\n",
    "$$sgn(x^r_i - x^r_j)$$ \n",
    "\n",
    "is in the following way:\n",
    "\n",
    "$$\n",
    " \\begin{cases} \n",
    "      -1  & x^r_i < x^r_j \\\\\n",
    "      0 & x^r_i = x^r_j \\\\\n",
    "      1 & x^r_i > x^r_j \n",
    "   \\end{cases}\n",
    "$$\n",
    "\n",
    "Therefore the possible results of \n",
    "\n",
    "$$sgn(x^r_i - x^r_j)sgn(y^r_i - y^r_j)$$\n",
    "\n",
    "are only 1, -1, or 0, which are summed to give an idea of the proportion of times the ranks of **x** and **y** are pointed in the right direction.\n",
    "\n",
    "##### 5. Write a function that takes in two vectors and returns Kendall's Tau.  You can then compare your answer to the built in function in scipy stats by using the assert statements in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kendalls_tau(x, y):\n",
    "    '''\n",
    "    INPUT\n",
    "    x - an array of matching length to array y\n",
    "    y - an array of matching length to array x\n",
    "    OUTPUT\n",
    "    tau - the kendall's tau for comparing x and y\n",
    "    '''    \n",
    "    # Change each vector to ranked values\n",
    "    x_r, y_r = x.rank(), y.rank()\n",
    "\n",
    "    n = len(x)\n",
    "    \n",
    "    frac = 2 / (n * (n-1))\n",
    "    \n",
    "    sum_vals = 0\n",
    "    \n",
    "    for i, (x_i, y_i) in enumerate(zip(x_r, y_r)):\n",
    "        for j, (x_j, y_j) in enumerate(zip(x_r, y_r)):\n",
    "            if i < j:\n",
    "                sum_vals += np.sign(x_i - x_j)*np.sign(y_i - y_j)\n",
    "                        \n",
    "    tau = sum_vals * frac\n",
    "    \n",
    "    return tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If this is all you see, it looks like you are all set!  Nice job coding up Kendall's Tau!\n"
     ]
    }
   ],
   "source": [
    "# This cell will test your function against the built in scipy function\n",
    "assert kendalls_tau(play_data['x1'], play_data['x2']) == kendalltau(play_data['x1'], play_data['x2'])[0], 'Oops!  The correlation between the first two columns should be 0, but your function returned {}.'.format(kendalls_tau(play_data['x1'], play_data['x2']))\n",
    "assert round(kendalls_tau(play_data['x1'], play_data['x3']), 2) == kendalltau(play_data['x1'], play_data['x3'])[0], 'Oops!  The correlation between the first and third columns should be {}, but your function returned {}.'.format(kendalltau(play_data['x1'], play_data['x3'])[0][1], kendalls_tau(play_data['x1'], play_data['x3']))\n",
    "assert round(kendalls_tau(play_data['x3'], play_data['x4']), 2) == round(kendalltau(play_data['x3'], play_data['x4'])[0], 2), 'Oops!  The correlation between the first and third columns should be {}, but your function returned {}.'.format(kendalltau(play_data['x3'], play_data['x4'])[0][1], kendalls_tau(play_data['x3'], play_data['x4']))\n",
    "print(\"If this is all you see, it looks like you are all set!  Nice job coding up Kendall's Tau!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Use your functions (and/or your knowledge of each of the above coefficients) to accurately identify each of the below statements as True or False.  **Note:** There may be some rounding differences due to the way numbers are stored, so it is recommended that you consider comparisons to 4 or fewer decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's right!  Pearson does not match the other two measures, as it looks specifically for linear relationships.  However, Spearman and Kenall's measures are exactly the same to one another in the cases related to play_data.\n"
     ]
    }
   ],
   "source": [
    "a = True\n",
    "b = False\n",
    "c = \"We can't be sure.\"\n",
    "\n",
    "\n",
    "corr_comp_dct = {\"For all columns of play_data, Spearman and Kendall's measures match.\": a,\n",
    "                \"For all columns of play_data, Spearman and Pearson's measures match.\": b, \n",
    "                \"For all columns of play_data, Pearson and Kendall's measures match.\": b\n",
    "}\n",
    "\n",
    "sim_6_sol(corr_comp_dct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance Measures\n",
    "\n",
    "All of the above measures are considered measures of correlation.  Similarly, there are distance measures (of which there are many).  [This is a great article](http://dataaspirant.com/2015/04/11/five-most-popular-similarity-measures-implementation-in-python/) on some popular distance metrics.  In this notebook, we will be looking specifically at two of these measures.  \n",
    "\n",
    "1. Euclidean Distance\n",
    "2. Manhattan Distance\n",
    "\n",
    "Different than the three measures you built functions for, these two measures take on values between 0 and potentially infinity.  Measures that are closer to 0 imply that two vectors are more similar to one another.  The larger these values become, the more dissimilar two vectors are to one another.\n",
    "\n",
    "Choosing one of these two `distance` metrics vs. one of the three `similarity` above is often a matter of personal preference, audience, and data specificities.  You will see in a bit a case where one of these measures (euclidean or manhattan distance) is optimal to using Pearson's correlation coefficient.\n",
    "\n",
    "### Euclidean Distance\n",
    "\n",
    "Euclidean distance can also just be considered as straight-line distance between two vectors.\n",
    "\n",
    "For two vectors **x** and **y**, we can compute this as:\n",
    "\n",
    "$$ EUC(\\textbf{x}, \\textbf{y}) = \\sqrt{\\sum\\limits_{i=1}^{n}(x_i - y_i)^2}$$\n",
    "\n",
    "### Manhattan Distance\n",
    "\n",
    "Different from euclidean distance, Manhattan distance is a 'manhattan block' distance from one vector to another.  Therefore, you can imagine this distance as a way to compute the distance between two points when you are not able to go through buildings.\n",
    "\n",
    "Specifically, this distance is computed as:\n",
    "\n",
    "$$ MANHATTAN(\\textbf{x}, \\textbf{y}) = \\sum\\limits_{i=1}^{n}|x_i - y_i|$$\n",
    "\n",
    "Using each of the above, write a function for each to take two vectors and compute the euclidean and manhattan distances.\n",
    "\n",
    "\n",
    "<img src=\"06_recommendation_engines/images/distances.png\">\n",
    "\n",
    "You can see in the above image, the **blue** line gives the **Manhattan** distance, while the **green** line gives the **Euclidean** distance between two points.\n",
    "\n",
    "##### 7. Use the below cell to complete a function for each distance metric.  Then test your functions against the built in values using the below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eucl_dist(x, y):\n",
    "    '''\n",
    "    INPUT\n",
    "    x - an array of matching length to array y\n",
    "    y - an array of matching length to array x\n",
    "    OUTPUT\n",
    "    euc - the euclidean distance between x and y\n",
    "    '''  \n",
    "    return np.linalg.norm(x - y)\n",
    "    \n",
    "def manhat_dist(x, y):\n",
    "    '''\n",
    "    INPUT\n",
    "    x - an array of matching length to array y\n",
    "    y - an array of matching length to array x\n",
    "    OUTPUT\n",
    "    manhat - the manhattan distance between x and y\n",
    "    '''  \n",
    "    return sum(abs(a - b) for a, b in zip(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your functions\n",
    "assert test_eucl(play_data['x1'], play_data['x2']) == eucl_dist(play_data['x1'], play_data['x2'])\n",
    "assert test_eucl(play_data['x2'], play_data['x3']) == eucl_dist(play_data['x2'], play_data['x3'])\n",
    "assert test_manhat(play_data['x1'], play_data['x2']) == manhat_dist(play_data['x1'], play_data['x2'])\n",
    "assert test_manhat(play_data['x2'], play_data['x3']) == manhat_dist(play_data['x2'], play_data['x3'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise Final Note\n",
    "\n",
    "It is worth noting that two vectors could be similar by metrics like the three at the top of the notebook, while being incredibly, incredibly different by measures like these final two.  Again, understanding your specific situation will assist in understanding whether your metric is appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 3 - Making Recommendations\n",
    "\n",
    "<center><img src='rec_09.png' width=350></center>\n",
    "\n",
    "Finalizing our neighborhood based recommendations, we need to use the ratings from our neighbors to influence the ratings we provide to other users.\n",
    "\n",
    "There are a few ways to do this, but a simple method would be to:\n",
    "1. Remove movies our user has already seen.\n",
    "2. Find ratings of the neighbors that are high.\n",
    "3. Recommend movies to each user where both 1 and 2 above hold.\n",
    "\n",
    "Other methods for making recommendations using collaborative filtering are based on weighting of the neighbors' ratings based on the 'closeness' of the neighbors.\n",
    "\n",
    "You can use each of the following two papers to learn more about this technique:\n",
    "1. [Domino Data Lab Paper](https://blog.dominodatalab.com/recommender-systems-collaborative-filtering/)\n",
    "2. [Semantic Scholar Paper On Weighted Ratings](https://pdfs.semanticscholar.org/3e9e/bcd9503ef7375c7bb334511804d1e45127e9.pdf)\n",
    "\n",
    "In the next section, you will implement the three-step process above to make recommendations for every user in the dataset. For computational reasons, you will notice that iterating this approach through all users has been done for you. But you will go through the process of implementing for individual pairs of users, which could easily be extended via looping to all users.\n",
    "\n",
    "<left><img src=\"rec_10.png\" width=350></left> \n",
    "Remove items already seen $\\rightarrow$ \n",
    "<left><img src=\"rec_11.png\" width=350></left>\n",
    "Remove items that similar users rated low $\\rightarrow$\n",
    "<left><img src=\"rec_12.png\" width=350></left><br>\n",
    "Maybe we only recommend movies rated 7 or higher as we are dealing with a 10-point scale<br>\n",
    "<left><img src=\"rec_13.png\" width=350></left><br>\n",
    "\n",
    "**Concluding of Identifying Recommendations:**\n",
    "<center><img src='rec_14.png' width=350></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4 - Recommendations with MovieTweetings: Collaborative Filtering\n",
    "\n",
    "One of the most popular methods for making recommendations is **collaborative filtering**.  In collaborative filtering, you are using the collaboration of user-item recommendations to assist in making new recommendations.  \n",
    "\n",
    "There are two main methods of performing collaborative filtering:\n",
    "\n",
    "1. **Neighborhood-Based Collaborative Filtering**, which is based on the idea that we can either correlate items that are similar to provide recommendations or we can correlate users to one another to provide recommendations.\n",
    "\n",
    "2. **Model Based Collaborative Filtering**, which is based on the idea that we can use machine learning and other mathematical models to understand the relationships that exist amongst items and users to predict ratings and provide ratings.\n",
    "\n",
    "\n",
    "In this notebook, you will be working on performing **neighborhood-based collaborative filtering**.  There are two main methods for performing collaborative filtering:\n",
    "\n",
    "1. **User-based collaborative filtering:** In this type of recommendation, users related to the user you would like to make recommendations for are used to create a recommendation.\n",
    "\n",
    "2. **Item-based collaborative filtering:** In this type of recommendation, first you need to find the items that are most related to each other item (based on similar ratings).  Then you can use the ratings of an individual on those similar items to understand if a user will like the new item.\n",
    "\n",
    "In this notebook you will be implementing **user-based collaborative filtering**.  However, it is easy to extend this approach to make recommendations using **item-based collaborative filtering**.  First, let's read in our data and necessary libraries.\n",
    "\n",
    "**NOTE**: Because of the size of the datasets, some of your code cells here will take a while to execute, so be patient!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>date</th>\n",
       "      <th>month_1</th>\n",
       "      <th>month_2</th>\n",
       "      <th>month_3</th>\n",
       "      <th>month_4</th>\n",
       "      <th>month_5</th>\n",
       "      <th>...</th>\n",
       "      <th>month_9</th>\n",
       "      <th>month_10</th>\n",
       "      <th>month_11</th>\n",
       "      <th>month_12</th>\n",
       "      <th>year_2013</th>\n",
       "      <th>year_2014</th>\n",
       "      <th>year_2015</th>\n",
       "      <th>year_2016</th>\n",
       "      <th>year_2017</th>\n",
       "      <th>year_2018</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>68646</td>\n",
       "      <td>10</td>\n",
       "      <td>1381620027</td>\n",
       "      <td>2013-10-12 23:20:27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>113277</td>\n",
       "      <td>10</td>\n",
       "      <td>1379466669</td>\n",
       "      <td>2013-09-18 01:11:09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>422720</td>\n",
       "      <td>8</td>\n",
       "      <td>1412178746</td>\n",
       "      <td>2014-10-01 15:52:26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>454876</td>\n",
       "      <td>8</td>\n",
       "      <td>1394818630</td>\n",
       "      <td>2014-03-14 17:37:10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>790636</td>\n",
       "      <td>7</td>\n",
       "      <td>1389963947</td>\n",
       "      <td>2014-01-17 13:05:47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating   timestamp                 date  month_1  \\\n",
       "0        1     68646      10  1381620027  2013-10-12 23:20:27        0   \n",
       "1        1    113277      10  1379466669  2013-09-18 01:11:09        0   \n",
       "2        2    422720       8  1412178746  2014-10-01 15:52:26        0   \n",
       "3        2    454876       8  1394818630  2014-03-14 17:37:10        0   \n",
       "4        2    790636       7  1389963947  2014-01-17 13:05:47        0   \n",
       "\n",
       "   month_2  month_3  month_4  month_5  ...  month_9  month_10  month_11  \\\n",
       "0        0        0        0        0  ...        0         1         0   \n",
       "1        0        0        0        0  ...        0         0         0   \n",
       "2        0        0        0        0  ...        0         1         0   \n",
       "3        0        0        0        0  ...        0         0         0   \n",
       "4        0        0        0        0  ...        0         0         0   \n",
       "\n",
       "   month_12  year_2013  year_2014  year_2015  year_2016  year_2017  year_2018  \n",
       "0         0          1          0          0          0          0          0  \n",
       "1         0          1          0          0          0          0          0  \n",
       "2         0          0          1          0          0          0          0  \n",
       "3         0          0          1          0          0          0          0  \n",
       "4         0          0          1          0          0          0          0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tests as t\n",
    "from scipy.sparse import csr_matrix\n",
    "from IPython.display import HTML\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Read in the datasets\n",
    "movies = pd.read_csv('06_recommendation_engines/movies_clean.csv')\n",
    "reviews = pd.read_csv('06_recommendation_engines/reviews_clean.csv')\n",
    "\n",
    "del movies['Unnamed: 0']\n",
    "del reviews['Unnamed: 0']\n",
    "\n",
    "display(reviews.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Measures of Similarity\n",
    "\n",
    "When using **neighborhood** based collaborative filtering, it is important to understand how to measure the similarity of users or items to one another.  \n",
    "\n",
    "There are a number of ways in which we might measure the similarity between two vectors (which might be two users or two items).  In this notebook, we will look specifically at two measures used to compare vectors:\n",
    "\n",
    "* **Pearson's correlation coefficient**\n",
    "\n",
    "Pearson's correlation coefficient is a measure of the strength and direction of a linear relationship. The value for this coefficient is a value between -1 and 1 where -1 indicates a strong, negative linear relationship and 1 indicates a strong, positive linear relationship. \n",
    "\n",
    "If we have two vectors x and y, we can define the correlation between the vectors as:\n",
    "\n",
    "\n",
    "$$\\text{CORR}(x, y) = \\frac{\\text{COV}(x, y)}{\\text{STDEV}(x)\\text{ }\\text{STDEV}(y)}$$\n",
    "\n",
    "where \n",
    "\n",
    "$$\\text{STDEV}(x) = \\sqrt{\\frac{1}{n-1}\\sum_{i=1}^{n}(x_i - \\bar{x})^2}$$\n",
    "\n",
    "and \n",
    "\n",
    "$$\\text{COV}(x, y) = \\frac{1}{n-1}\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})$$\n",
    "\n",
    "where n is the length of the vector, which must be the same for both x and y and $\\bar{x}$ is the mean of the observations in the vector.  \n",
    "\n",
    "We can use the correlation coefficient to indicate how alike two vectors are to one another, where the closer to 1 the coefficient, the more alike the vectors are to one another.  There are some potential downsides to using this metric as a measure of similarity.  You will see some of these throughout this workbook.\n",
    "\n",
    "\n",
    "* **Euclidean distance**\n",
    "\n",
    "Euclidean distance is a measure of the straightline distance from one vector to another.  Because this is a measure of distance, larger values are an indication that two vectors are different from one another (which is different than Pearson's correlation coefficient).\n",
    "\n",
    "Specifically, the euclidean distance between two vectors x and y is measured as:\n",
    "\n",
    "$$ \\text{EUCL}(x, y) = \\sqrt{\\sum_{i=1}^{n}(x_i - y_i)^2}$$\n",
    "\n",
    "Different from the correlation coefficient, no scaling is performed in the denominator.  Therefore, you need to make sure all of your data are on the same scale when using this metric.\n",
    "\n",
    "**Note:** Because measuring similarity is often based on looking at the distance between vectors, it is important in these cases to scale your data or to have all data be in the same scale.  If some measures are on a 5 point scale, while others are on a 100 point scale, you are likely to have non-optimal results due to the difference in variability of your features.  In this case, we will not need to scale data because they are all on a 10 point scale, but it is always something to keep in mind!\n",
    "\n",
    "------------\n",
    "\n",
    "### User-Item Matrix\n",
    "\n",
    "In order to calculate the similarities, it is common to put values in a matrix.  In this matrix, users are identified by each row, and items are represented by columns.  \n",
    "\n",
    "\n",
    "![alt text](06_recommendation_engines/images/userxitem.png \"User Item Matrix\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above matrix, you can see that **User 1** and **User 2** both used **Item 1**, and **User 2**, **User 3**, and **User 4** all used **Item 2**.  However, there are also a large number of missing values in the matrix for users who haven't used a particular item.  A matrix with many missing values (like the one above) is considered **sparse**.\n",
    "\n",
    "Our first goal for this notebook is to create the above matrix with the **reviews** dataset.  However, instead of 1 values in each cell, you should have the actual rating.  \n",
    "\n",
    "The users will indicate the rows, and the movies will exist across the columns. To create the user-item matrix, we only need the first three columns of the **reviews** dataframe, which you can see by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>68646</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>113277</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>422720</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>454876</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>790636</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating\n",
       "0        1     68646      10\n",
       "1        1    113277      10\n",
       "2        2    422720       8\n",
       "3        2    454876       8\n",
       "4        2    790636       7"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_items = reviews[['user_id', 'movie_id', 'rating']]\n",
    "user_items.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the User-Item Matrix\n",
    "\n",
    "In order to create the user-items matrix (like the one above), I personally started by using a [pivot table](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.pivot_table.html). \n",
    "\n",
    "However, I quickly ran into a memory error (a common theme throughout this notebook).  I will help you navigate around many of the errors I had, and achieve useful collaborative filtering results! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Create a matrix where the users are the rows, the movies are the columns, and the ratings exist in each cell, or a NaN exists in cells where a user hasn't rated a particular movie. If you get a memory error (like I did), [this link here](https://stackoverflow.com/questions/39648991/pandas-dataframe-pivot-memory-error) might help you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movie_id</th>\n",
       "      <th>8</th>\n",
       "      <th>10</th>\n",
       "      <th>12</th>\n",
       "      <th>25</th>\n",
       "      <th>91</th>\n",
       "      <th>417</th>\n",
       "      <th>439</th>\n",
       "      <th>443</th>\n",
       "      <th>628</th>\n",
       "      <th>833</th>\n",
       "      <th>...</th>\n",
       "      <th>8144778</th>\n",
       "      <th>8144868</th>\n",
       "      <th>8206708</th>\n",
       "      <th>8289196</th>\n",
       "      <th>8324578</th>\n",
       "      <th>8335880</th>\n",
       "      <th>8342748</th>\n",
       "      <th>8342946</th>\n",
       "      <th>8402090</th>\n",
       "      <th>8439854</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31245 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movie_id  8        10       12       25       91       417      439      \\\n",
       "user_id                                                                   \n",
       "1             NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "2             NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "3             NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "4             NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "5             NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "\n",
       "movie_id  443      628      833      ...  8144778  8144868  8206708  8289196  \\\n",
       "user_id                              ...                                       \n",
       "1             NaN      NaN      NaN  ...      NaN      NaN      NaN      NaN   \n",
       "2             NaN      NaN      NaN  ...      NaN      NaN      NaN      NaN   \n",
       "3             NaN      NaN      NaN  ...      NaN      NaN      NaN      NaN   \n",
       "4             NaN      NaN      NaN  ...      NaN      NaN      NaN      NaN   \n",
       "5             NaN      NaN      NaN  ...      NaN      NaN      NaN      NaN   \n",
       "\n",
       "movie_id  8324578  8335880  8342748  8342946  8402090  8439854  \n",
       "user_id                                                         \n",
       "1             NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "2             NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "3             NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "4             NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "5             NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "\n",
       "[5 rows x 31245 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_by_movie = user_items.groupby(['user_id', 'movie_id'])['rating'].max().unstack()\n",
    "user_by_movie.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check your results below to make sure your matrix is ready for the upcoming sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looks like you are all set! Proceed!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"06_recommendation_engines/images/greatjob.webp\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert movies.shape[0] == user_by_movie.shape[1], \"Oh no! Your matrix should have {} columns, and yours has {}!\".format(movies.shape[0], user_by_movie.shape[1])\n",
    "assert reviews.user_id.nunique() == user_by_movie.shape[0], \"Oh no! Your matrix should have {} rows, and yours has {}!\".format(reviews.user_id.nunique(), user_by_movie.shape[0])\n",
    "print(\"Looks like you are all set! Proceed!\")\n",
    "HTML('<img src=\"06_recommendation_engines/images/greatjob.webp\">')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Now that you have a matrix of users by movies, use this matrix to create a dictionary where the key is each user and the value is an array of the movies each user has rated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with users and corresponding movies seen\n",
    "\n",
    "def movies_watched(user_id):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - the user_id of an individual as int\n",
    "    OUTPUT:\n",
    "    movies - an array of movies the user has watched\n",
    "    '''\n",
    "    movies = user_by_movie.loc[user_id].dropna().index.values\n",
    "\n",
    "    return movies\n",
    "\n",
    "\n",
    "def create_user_movie_dict():\n",
    "    '''\n",
    "    INPUT: None\n",
    "    OUTPUT: movies_seen - a dictionary where each key is a user_id and the value is an array of movie_ids\n",
    "    \n",
    "    Creates the movies_seen dictionary\n",
    "    '''\n",
    "    movies_seen = {}\n",
    "    for i in user_by_movie.index:\n",
    "        movies_seen[i] = movies_watched(i)\n",
    "    return movies_seen\n",
    "\n",
    "\n",
    "\n",
    "# Use your function to return dictionary\n",
    "movies_seen = create_user_movie_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. If a user hasn't rated more than 2 movies, we consider these users \"too new\".  Create a new dictionary that only contains users who have rated more than 2 movies.  This dictionary will be used for all the final steps of this workbook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove individuals who have watched 2 or fewer movies - don't have enough data to make recs\n",
    "\n",
    "def create_movies_to_analyze(movies_seen, lower_bound=2):\n",
    "    '''\n",
    "    INPUT:  \n",
    "    movies_seen - a dictionary where each key is a user_id and the value is an array of movie_ids\n",
    "    lower_bound - (an int) a user must have more movies seen than the lower bound to be added to the movies_to_analyze dictionary\n",
    "\n",
    "    OUTPUT: \n",
    "    movies_to_analyze - a dictionary where each key is a user_id and the value is an array of movie_ids\n",
    "    \n",
    "    The movies_seen and movies_to_analyze dictionaries should be the same except that the output dictionary has removed \n",
    "    \n",
    "    '''\n",
    "    movies_to_analyze = {}\n",
    "    \n",
    "    for i in movies_seen.keys():\n",
    "        if len(movies_seen[i]) > lower_bound:\n",
    "            movies_to_analyze[i] = movies_seen[i]\n",
    "    \n",
    "    return movies_to_analyze\n",
    "\n",
    "\n",
    "# Use your function to return your updated dictionary\n",
    "movies_to_analyze = create_movies_to_analyze(movies_seen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If this is all you see, you are good to go!\n"
     ]
    }
   ],
   "source": [
    "# Run the tests below to check that your movies_to_analyze matches the solution\n",
    "assert len(movies_to_analyze) == 23512, \"Oops!  It doesn't look like your dictionary has the right number of individuals.\"\n",
    "assert len(movies_to_analyze[2]) == 23, \"Oops!  User 2 didn't match the number of movies we thought they would have.\"\n",
    "assert len(movies_to_analyze[7])  == 3, \"Oops!  User 7 didn't match the number of movies we thought they would have.\"\n",
    "print(\"If this is all you see, you are good to go!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating User Similarities\n",
    "\n",
    "Now that you have set up the **movies_to_analyze** dictionary, it is time to take a closer look at the similarities between users.  Below is the pseudocode for how I thought about determining the similarity between users:\n",
    "\n",
    "```\n",
    "for user1 in movies_to_analyze\n",
    "    for user2 in movies_to_analyze\n",
    "        see how many movies match between the two users\n",
    "        if more than two movies in common\n",
    "            pull the overlapping movies\n",
    "            compute the distance/similarity metric between ratings on the same movies for the two users\n",
    "            store the users and the distance metric\n",
    "```\n",
    "\n",
    "However, this took a very long time to run, and other methods of performing these operations did not fit on the workspace memory!\n",
    "\n",
    "Therefore, rather than creating a dataframe with all possible pairings of users in our data, your task for this question is to look at a few specific examples of the correlation between ratings given by two users.  For this question consider you want to compute the [correlation](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.corr.html) between users.\n",
    "\n",
    "`4.` Using the **movies_to_analyze** dictionary and **user_by_movie** dataframe, create a function that computes the correlation between the ratings of similar movies for two users.  Then use your function to compare your results to ours using the tests below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_correlation(user1, user2):\n",
    "    '''\n",
    "    INPUT\n",
    "    user1 - int user_id\n",
    "    user2 - int user_id\n",
    "    OUTPUT\n",
    "    the correlation between the matching ratings between the two users\n",
    "    '''\n",
    "    # retrieve movies for each user\n",
    "    movies1 = movies_to_analyze[user1]\n",
    "    movies2 = movies_to_analyze[user2]\n",
    "    \n",
    "    \n",
    "    # Find Shared Movies\n",
    "    shared_movs = np.intersect1d(movies1, movies2, assume_unique=True)\n",
    "    \n",
    "    # Calculate correlation between the users\n",
    "    df = user_by_movie.loc[(user1, user2), shared_movs]\n",
    "    corr = df.transpose().corr().iloc[0,1]\n",
    "    \n",
    "    return corr #return the correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If this is all you see, then it looks like your function passed all of our tests!\n"
     ]
    }
   ],
   "source": [
    "# Test your function against the solution\n",
    "assert compute_correlation(2,2) == 1.0, \"Oops!  The correlation between a user and itself should be 1.0.\"\n",
    "assert round(compute_correlation(2,66), 2) == 0.76, \"Oops!  The correlation between user 2 and 66 should be about 0.76.\"\n",
    "assert np.isnan(compute_correlation(2,104)), \"Oops!  The correlation between user 2 and 104 should be a NaN.\"\n",
    "\n",
    "print(\"If this is all you see, then it looks like your function passed all of our tests!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why the NaN's?\n",
    "\n",
    "If the function you wrote passed all of the tests, then you have correctly set up your function to calculate the correlation between any two users.  \n",
    "\n",
    "##### 5. But one question is, why are we still obtaining **NaN** values?  As you can see in the code cell above, users 2 and 104 have a correlation of **NaN**. Why?\n",
    "\n",
    "Think and write your ideas here about why these NaNs exist, and use the cells below to do some coding to validate your thoughts. You can check other pairs of users and see that there are actually many NaNs in our data - 2,526,710 of them in fact. These NaN's ultimately make the correlation coefficient a less than optimal measure of similarity between two users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 454876,  816711, 1454468, 1535109])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.intersect1d(movies_to_analyze[2], movies_to_analyze[104], assume_unique=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movie_id</th>\n",
       "      <th>454876</th>\n",
       "      <th>816711</th>\n",
       "      <th>1454468</th>\n",
       "      <th>1535109</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "movie_id  454876   816711   1454468  1535109\n",
       "user_id                                     \n",
       "2             8.0      8.0      8.0      8.0\n",
       "104           9.0      7.0      7.0      9.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_by_movie.loc[(2, 104), np.intersect1d(movies_to_analyze[2], movies_to_analyze[104], assume_unique=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation is $\\text{CORR}(\\textbf{x}, \\textbf{y}) = \\frac{\\sum\\limits_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum\\limits_{i=1}^{n}(x_i-\\bar{x})^2}\\sqrt{\\sum\\limits_{i=1}^{n}(y_i-\\bar{y})^2}}$\n",
    "\n",
    "If we let $i$ be associated with `user_id 2`, then note all rating values for this user are the same. So, $\\sum\\limits_{i=1}^{n}(x_i - \\bar{x}) = 0$ and $\\sqrt{\\sum\\limits_{i=1}^{n}(y_i-\\bar{y})^{2}}=0$. So, we get $\\frac{0}{0}=\\text{DNE}$ which is `NaN`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which movies did both user 2 and user 104 see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{454876, 816711, 1454468, 1535109}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(movies_to_analyze[2]).intersection(set(movies_to_analyze[104]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What were the ratings for each user for those movies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movie_id</th>\n",
       "      <th>454876</th>\n",
       "      <th>816711</th>\n",
       "      <th>1454468</th>\n",
       "      <th>1535109</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "movie_id  454876   816711   1454468  1535109\n",
       "user_id                                     \n",
       "2             8.0      8.0      8.0      8.0\n",
       "104           9.0      7.0      7.0      9.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_by_movie.loc[(2, 104), np.intersect1d(movies_to_analyze[2], movies_to_analyze[104], assume_unique=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Because the correlation coefficient proved to be less than optimal for relating user ratings to one another, we could instead calculate the euclidean distance between the ratings.  I found [this post](https://stackoverflow.com/questions/1401712/how-can-the-euclidean-distance-be-calculated-with-numpy) particularly helpful when I was setting up my function.  This function should be very similar to your previous function.  When you feel confident with your function, test it against our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_euclidean_dist(user1, user2):\n",
    "    '''\n",
    "    INPUT\n",
    "    user1 - int user_id\n",
    "    user2 - int user_id\n",
    "    OUTPUT\n",
    "    the euclidean distance between user1 and user2\n",
    "    '''\n",
    "    # Pull movies for each user\n",
    "    movies1 = movies_to_analyze[user1]\n",
    "    movies2 = movies_to_analyze[user2]\n",
    "    \n",
    "    \n",
    "    # Find Similar Movies\n",
    "    sim_movs = np.intersect1d(movies1, movies2, assume_unique=True)\n",
    "    \n",
    "    # Calculate euclidean distance between the users\n",
    "    df = user_by_movie.loc[(user1, user2), sim_movs]\n",
    "    dist = np.linalg.norm(df.loc[user1] - df.loc[user2])\n",
    "    \n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in solution euclidean distances\n",
    "import pickle\n",
    "df_dists = pd.read_pickle(\"06_recommendation_engines/data/Term2/recommendations/lesson1/data/dists.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If this is all you see, then it looks like your function passed all of our tests!\n"
     ]
    }
   ],
   "source": [
    "# Test your function against the solution\n",
    "assert compute_euclidean_dist(2,2) == df_dists.query(\"user1 == 2 and user2 == 2\")['eucl_dist'][0], \"Oops!  The distance between a user and itself should be 0.0.\"\n",
    "assert round(compute_euclidean_dist(2,66), 2) == round(df_dists.query(\"user1 == 2 and user2 == 66\")['eucl_dist'][1], 2), \"Oops!  The distance between user 2 and 66 should be about 2.24.\"\n",
    "assert np.isnan(compute_euclidean_dist(2,104)) == np.isnan(df_dists.query(\"user1 == 2 and user2 == 104\")['eucl_dist'][4]), \"Oops!  The distance between user 2 and 104 should be 2.\"\n",
    "\n",
    "print(\"If this is all you see, then it looks like your function passed all of our tests!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Nearest Neighbors to Make Recommendations\n",
    "\n",
    "In the previous question, you read in **df_dists**. Therefore, you have a measure of distance between each user and every other user. This dataframe holds every possible pairing of users, as well as the corresponding euclidean distance.\n",
    "\n",
    "Because of the **NaN** values that exist within the correlations of the matching ratings for many pairs of users, as we discussed above, we will proceed using **df_dists**. You will want to find the users that are 'nearest' each user.  Then you will want to find the movies the closest neighbors have liked to recommend to each user.\n",
    "\n",
    "I made use of the following objects:\n",
    "\n",
    "* df_dists (to obtain the neighbors)\n",
    "* user_items (to obtain the movies the neighbors and users have rated)\n",
    "* movies (to obtain the names of the movies)\n",
    "\n",
    "##### 7. Complete the functions below, which allow you to find the recommendations for any user.  There are five functions which you will need:\n",
    "\n",
    "* **find_closest_neighbors** - this returns a list of user_ids from closest neighbor to farthest neighbor using euclidean distance\n",
    "\n",
    "\n",
    "* **movies_liked** - returns an array of movie_ids\n",
    "\n",
    "\n",
    "* **movie_names** - takes the output of movies_liked and returns a list of movie names associated with the movie_ids\n",
    "\n",
    "\n",
    "* **make_recommendations** - takes a user id and goes through closest neighbors to return a list of movie names as recommendations\n",
    "\n",
    "\n",
    "* **all_recommendations** = loops through every user and returns a dictionary of with the key as a user_id and the value as a list of movie recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 23512/23512 [18:10<00:00, 21.56it/s]\n"
     ]
    }
   ],
   "source": [
    "def find_closest_neighbors(user):\n",
    "    '''\n",
    "    INPUT:\n",
    "        user - (int) the user_id of the individual you want to find the closest users\n",
    "    OUTPUT:\n",
    "        closest_neighbors - an array of the id's of the users sorted from closest to farthest away\n",
    "    '''\n",
    "    # I treated ties as arbitrary and just kept whichever was easiest to keep using the head method\n",
    "    \n",
    "    closest_users = df_dists[df_dists['user1']==user].sort_values(by='eucl_dist').iloc[1:]['user2']\n",
    "    closest_neighbors = np.array(closest_users)\n",
    "    \n",
    "    return closest_neighbors\n",
    "    \n",
    "    \n",
    "    \n",
    "def movies_liked(user_id, min_rating=7):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - the user_id of an individual as int\n",
    "    min_rating - the minimum rating considered while still a movie is still a \"like\" and not a \"dislike\"\n",
    "    OUTPUT:\n",
    "    movies_liked - an array of movies the user has watched and liked\n",
    "    '''\n",
    "    movies_liked = np.array(user_items.query('user_id == @user_id and rating > (@min_rating -1)')['movie_id'])\n",
    "    \n",
    "    return movies_liked\n",
    "\n",
    "\n",
    "def movie_names(movie_ids):\n",
    "    '''\n",
    "    INPUT\n",
    "    movie_ids - a list of movie_ids\n",
    "    OUTPUT\n",
    "    movies - a list of movie names associated with the movie_ids\n",
    "    \n",
    "    '''\n",
    "    movie_lst = list(movies[movies['movie_id'].isin(movie_ids)]['movie'])\n",
    "   \n",
    "    return movie_lst\n",
    "    \n",
    "    \n",
    "def make_recommendations(user, num_recs=10):\n",
    "    '''\n",
    "    INPUT:\n",
    "        user - (int) a user_id of the individual you want to make recommendations for\n",
    "        num_recs - (int) number of movies to return\n",
    "    OUTPUT:\n",
    "        recommendations - a list of movies - if there are \"num_recs\" recommendations return this many\n",
    "                          otherwise return the total number of recommendations available for the \"user\"\n",
    "                          which may just be an empty list\n",
    "    '''\n",
    "    # I wanted to make recommendations by pulling different movies than the user has already seen\n",
    "    # Go in order from closest to farthest to find movies you would recommend\n",
    "    # I also only considered movies where the closest user rated the movie as a 9 or 10\n",
    "    \n",
    "    # movies_seen by user (we don't want to recommend these)\n",
    "    movies_seen = movies_watched(user)\n",
    "    # users closest neighbor array from closest to furthest\n",
    "    closest_neighbors = find_closest_neighbors(user)\n",
    "    \n",
    "    # Keep the recommended movies here\n",
    "    recs = np.array([])\n",
    "    \n",
    "    # Go through the neighbors and identify movies they like the user hasn't seen\n",
    "    for neighbor in closest_neighbors:\n",
    "        # list of movies the neighbor rated above 7\n",
    "        neighbs_likes = movies_liked(neighbor)\n",
    "        \n",
    "        #Obtain recommendations for each neighbor\n",
    "        new_recs = np.setdiff1d(neighbs_likes, movies_seen, assume_unique=True)\n",
    "        \n",
    "        # Update recs with new recs\n",
    "        recs = np.unique(np.concatenate([new_recs, recs], axis=0))\n",
    "        \n",
    "        # If we have enough recommendations exit the loop\n",
    "        if len(recs) > num_recs-1:\n",
    "            break\n",
    "    \n",
    "    # Pull movie titles using movie ids\n",
    "    recommendations = movie_names(recs)\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "def all_recommendations(num_recs=10):\n",
    "    '''\n",
    "    INPUT \n",
    "        num_recs (int) the (max) number of recommendations for each user\n",
    "    OUTPUT\n",
    "        all_recs - a dictionary where each key is a user_id and the value is an array of recommended movie titles\n",
    "    '''\n",
    "    \n",
    "    # All the users we need to make recommendations for\n",
    "    users = np.unique(df_dists['user1'])\n",
    "    n_users = len(users)\n",
    "    \n",
    "    #Store all recommendations in this dictionary\n",
    "    all_recs = dict()\n",
    "    \n",
    "    # Make the recommendations for each user\n",
    "    for user in tqdm(users):\n",
    "        all_recs[user] = make_recommendations(user, num_recs)\n",
    "    \n",
    "    return all_recs\n",
    "\n",
    "all_recs = all_recommendations(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loads our solution dictionary so you can compare results\n",
    "all_recs_sol = pd.read_pickle(\"06_recommendation_engines/data/Term2/recommendations/lesson1/data/all_recs.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you made it here, you now have recommendations for many users using collaborative filtering!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"06_recommendation_engines/images/greatjob.webp\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert all_recs[2] == make_recommendations(2), \"Oops!  Your recommendations for user 2 didn't match ours.\"\n",
    "assert all_recs[26] == make_recommendations(26), \"Oops!  It actually wasn't possible to make any recommendations for user 26.\"\n",
    "assert all_recs[1503] == make_recommendations(1503), \"Oops! Looks like your solution for user 1503 didn't match ours.\"\n",
    "print(\"If you made it here, you now have recommendations for many users using collaborative filtering!\")\n",
    "HTML('<img src=\"06_recommendation_engines/images/greatjob.webp\">')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now What?\n",
    "\n",
    "If you made it this far, you have successfully implemented a solution to making recommendations using collaborative filtering. \n",
    "\n",
    "##### 8. Let's do a quick recap of the steps taken to obtain recommendations using collaborative filtering.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"That's right! All of your solutions look good!\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check your understanding of the results by correctly filling in the dictionary below\n",
    "a = \"pearson's correlation and spearman's correlation\"\n",
    "b = 'item based collaborative filtering'\n",
    "c = \"there were too many ratings to get a stable metric\"\n",
    "d = 'user based collaborative filtering'\n",
    "e = \"euclidean distance and pearson's correlation coefficient\"\n",
    "f = \"manhattan distance and euclidean distance\"\n",
    "g = \"spearman's correlation and euclidean distance\"\n",
    "h = \"the spread in some ratings was zero\"\n",
    "i = 'content based recommendation'\n",
    "\n",
    "sol_dict = {\n",
    "    'The type of recommendation system implemented here was a ...': d,\n",
    "    'The two methods used to estimate user similarity were: ': e,\n",
    "    'There was an issue with using the correlation coefficient.  What was it?': h\n",
    "}\n",
    "\n",
    "test_recs(sol_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, let's take a closer look at some of the results.  There are two solution files that you read in to check your results, and you created these objects\n",
    "\n",
    "* **df_dists** - a dataframe of user1, user2, euclidean distance between the two users\n",
    "* **all_recs_sol** - a dictionary of all recommendations (key = user, value = list of recommendations)  \n",
    "\n",
    "`9.` Use these two objects along with the cells below to correctly fill in the dictionary below and complete this notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1319"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Array will be empty if no recommendations\n",
    "len([v for v in all_recs_sol.values() if len(v)==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distance cant be calculated if missing\n",
    "df_dists['eucl_dist'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1325"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only recommended movies if there were >= 10 recommendations\n",
    "len([v for v in all_recs_sol.values() if len(v)<10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"That's right! All of your solutions look good!\""
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 567\n",
    "b = 1503\n",
    "c = 1319 # len([v for v in all_recs_sol.values() if len(v)==0])\n",
    "d = 1325 # len([v for v in all_recs_sol.values() if len(v)<10])\n",
    "e = 2526710 # Would need to see where all ratings are the same where any user overlaps with any other user - cannot rely on the row being\n",
    "# the same alone, like df.eq(df.iloc[:, 0], axis=0).all(1), because it depends on the overlap, but df.eq(df.iloc[:, 0], axis=0).all(1), \n",
    "# would at least tell you where the overlap doesnt matter, i.e. the ability to calculate the correlation depends on 1) overlapping movies\n",
    "# 2) ratings of those overlapping movies - not calculating\n",
    "f = 0 # df_dists['eucl_dist'].isna().sum()\n",
    "g = 'Use another method to make recommendations - content based, knowledge based, or model based collaborative filtering'\n",
    "\n",
    "sol_dict2 = {\n",
    "    'For how many pairs of users were we not able to obtain a measure of similarity using correlation?': e,\n",
    "    'For how many pairs of users were we not able to obtain a measure of similarity using euclidean distance?': f,\n",
    "    'For how many users were we unable to make any recommendations for using collaborative filtering?': c,\n",
    "    'For how many users were we unable to make 10 recommendations for using collaborative filtering?': d,\n",
    "    'What might be a way for us to get 10 recommendations for every user?': g}\n",
    "\n",
    "test_recs2(sol_dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_ud",
   "language": "python",
   "name": "venv_ud"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
