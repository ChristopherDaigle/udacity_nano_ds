{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Factorization for Recommendations\n",
    "\n",
    "## Topics\n",
    "\n",
    "In this lesson, you will learn about three main topics:\n",
    "1. We will look from a high level at how you might go about validating your recommendations.\n",
    "2. We will look at matrix factorization as a method to use machine learning to make recommendations.\n",
    "3. We will look at combining recommendation techniques to make predictions to existing and new users and for existing and new items.\n",
    "\n",
    "As we go through this lesson, you will come to realize that there are a lot of difficulties in working with recommendation engines which make them still an exciting field to study! This is especially true when you combine your recommendations with a specific product type.\n",
    "\n",
    "Recommending movies, recommending restaurants, or recommending clothing might happen in a number of different ways. However, the techniques you will learn in this lesson are often extendable to any of these cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing Data For Recommendations\n",
    "\n",
    "In the last lesson, you were making recommendations by providing a list of popular items, or a list of items that the user hadn't observed but that someone with similar tastes had observed. However, understanding if these recommendations are good in practice means that you have to deploy these recommendations to users and see how it impacts your metrics (sales, higher engagement, clicks, conversions, etc.).\n",
    "\n",
    "You may not want your recommendations to go live to understand how well they work. In these cases, you will want to split your data into training and testing portions. In these cases, you can train your recommendation engine on a subset of the data, then you can test how well your recommendation engine performs on a test set of data before deploying your model to the world.\n",
    "\n",
    "However, the cases you saw in the last lesson, where just a list of recommendations was provided, don't actually lend themselves very well to training and testing methods of evaluation. In the next upcoming pages, you will be introduced to matrix factorization, which actually does work quite well for these situations.\n",
    "\n",
    "If you have user data from before and after the recommendations, you can evaluate a metric on pre and post recommendation data\n",
    "<center><img src='mat_fact_01.png' width=500></center>\n",
    "\n",
    "If you dont have user data, or if you have new users, you may need to think of another way, like predicting what they would rate other movies. Some assumptions about this will follow.\n",
    "<center><img src='mat_fact_02.png' width=500></center>\n",
    "\n",
    "## Common Method - Singular Value Decomposition (SVD):\n",
    "\n",
    "* Provide a predicted rating value, not a list of recommendations\n",
    "* Can use regression based metrics like MSE or MAE to assess performance\n",
    "* Metrics can be understood before deploying our recommendations to our customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating Your Recommendations\n",
    "\n",
    "### Online Testing\n",
    "\n",
    "For online methods of testing a recommender's performance, many of the methods you saw in the previous lesson work very well - you can deploy your recommendations and just watch your metrics carefully. It is common in practice to set up online recommendations to have an \"old\" version of recommended items, which is compared to a new page that uses a new recommendation strategy.\n",
    "\n",
    "All ideas associated with A/B testing that you learned in the earlier lessons are critical to watching your metrics in online learning, and ultimately, choosing a recommendation strategy that works best for your products and customers.\n",
    "\n",
    "### Offline Testing\n",
    "\n",
    "In many cases, a company might not let you simply deploy your recommendations out into the real world any time you feel like it. Testing out your recommendations in a training-testing environment prior to deploying them is called **offline** testing.\n",
    "\n",
    "The recommendation methods you built in the previous lesson actually don't work very well for offline testing. In offline testing, it is ideal to not just obtain a list of recommendations for each individual, because we ultimately don't know if a user doesn't use an item because they don't like it, or because they just haven't used it yet (but would like it). Rather, it would be great if we have an idea of how much each user would like each item using a predicted rating. Then we can compare this predicted rating to the actual rating any individual gives to an item in the future.\n",
    "\n",
    "In the previous video, you saw an example of a user to whom we gave a list of movies that they still hadn't seen. Therefore, we couldn't tell how well we were doing with our recommendations. Techniques related to matrix factorization lend themselves nicely to solving this problem.\n",
    "\n",
    "### User Groups\n",
    "\n",
    "The final (possible) method of validating your recommendations is by having user groups give feedback on items you would recommend for them. Obtaining good user groups that are representative of your customers can be a challenge on its own. This is especially true when you have a lot of products and a very large consumer base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz Question\n",
    "\n",
    "For each metric below, identify whether the metric is generally used for **regression** or **classification**. In offline methods of looking at the results of our recommendations systems, we often are able to use the metrics associated with regression or classification algorithms.\n",
    "\n",
    "<center><img src='mat_fact_03.png' width=500></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Singular Value Decomposition - SVD\n",
    "\n",
    "In the next part of this lesson, you will first get exposure to Singular Value Decomposition, or SVD. We will soon see why this technique falls short for many recommendation problems. However, understanding traditional SVD approaches to matrix factorization is useful as a start to a number of matrix factorization techniques that are possible in practice.\n",
    "\n",
    "In order to implement SVD for many recommendation engines, we will need to use a slightly modified approach known as FunkSVD. This approach proved to work incredibly well during the [Netflix competition](https://en.wikipedia.org/wiki/Netflix_Prize), and therefore, it is one of the most popular recommendation approaches in use today.\n",
    "\n",
    "Let's first take a closer look at traditional SVD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Factors\n",
    "\n",
    "* **Latent Factor:** Feature that isn't actually observed in the data, but can be inferred based on the relationships that occur\n",
    "<center><img src=\"mat_fact_04.png\" width=500></center>\n",
    "\n",
    "When performing SVD, we create a matrix of users by items (or customers by movies in our specific example), with user ratings for each item scattered throughout the matrix. An example is shown in the image below.\n",
    "<center><img src=\"mat_fact_05.png\" width=500></center>\n",
    "\n",
    "You can see that this matrix doesn't have any specific information about the users or items. Rather, it just holds the ratings that each user gave to each item. Using SVD on this matrix, we can find **latent features** related to the movies and customers. This is amazing because the dataset doesn't contain any information about the customers or movies!\n",
    "\n",
    "### Latent Factor Question\n",
    "\n",
    "Imagine a situation in which you collect 1-5 ratings data from a bunch of people related to how they feel about lots of different animals (birds, horses, cats, dogs, etc.). What are some examples of possible latent factors you might observe in this ratings data?\n",
    "* The observed ratings values\n",
    "* **The size of the animal**\n",
    "* **How many legs the animal has**\n",
    "* **Whether the animal can fly or not**\n",
    "> The ratings are observed, so they are not latent! However, the other three variables are latent in that we wouldn't have raw data on these values by just collecting ratings of how a user feels about each animal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Singular Value Decomposition\n",
    "\n",
    "Let's do a quick check of understanding. If we let AA be our user-item matrix, we can write the decomposition of that matrix in the following way.\n",
    "\n",
    "$$A = U \\Sigma V^{T}$$ \n",
    "\n",
    "Use the quizzes below to test your understanding of what these matrices represent, as well as the dimensions of these matrices.<br>\n",
    "<left><img src=\"mat_fact_06.png\" width=500></left> $ \\rightarrow$ <right><img src=\"mat_fact_07.png\" width=500></right>\n",
    "\n",
    "#### $U$: index (users) relationship to latent features\n",
    "<center><img src=\"mat_fact_08.png\" width=500></center>\n",
    "\n",
    "#### $V$: item (movies) relationship to latent features\n",
    "<center><img src=\"mat_fact_09.png\" width=500></center>\n",
    "\n",
    "#### $\\Sigma$: matrix of relationship to latent features importance to reconstructing original matrix\n",
    "\n",
    "* Has the same number of rows and columns (k) as the number of latent factors you decide to keep (e.g. 3: AI, dogs, sad)\n",
    "* Values of matrix are in descending order\n",
    "* Off-diagonal values are zero\n",
    "\n",
    "<left><img src=\"mat_fact_10.png\" width=500></left> $\\rightarrow$ <right><img src=\"mat_fact_11.png\" width=500></right>\n",
    "\n",
    "#### Combining:\n",
    "<left><img src=\"mat_fact_12.png\" width=500></left> $\\rightarrow$ <right><img src=\"mat_fact_13.png\" width=500></right>\n",
    "\n",
    "#### Quiz:\n",
    "<center><img src=\"mat_fact_14.png\" width=500></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Singular Value Decomposition Takeaways\n",
    "Three main takeaways [from the previous notebook](07_matrix_factorization/1_Intro_to_SVD.ipynb):\n",
    "\n",
    "#### 1. **The latent factors retrieved from SVD aren't actually labeled.**\n",
    "There will not be a clear labeling of latent features (it will require investigation to understand)\n",
    "\n",
    "<center><img src=\"mat_fact_16.png\" width=500></center>\n",
    "\n",
    "\n",
    "#### 2. We can get an idea of how many latent factors we might want to keep by using the Sigma matrix.\n",
    "\n",
    "The sum of squared diagonal elements tells us the total variability to be explained in the matrix.\n",
    "\n",
    "By separating the elements, we can see which latent features explain the most variability; we may not need all of them to reconstruct the original matrix\n",
    "\n",
    "<center><img src=\"mat_fact_15.png\" width=500></center>\n",
    "\n",
    "#### 3. SVD in NumPy will not work when our matrix has missing values. This makes this technique less than useful for our current user-movie matrix.\n",
    "\n",
    "Most matrices will not be completely filled. Without that, we cannot discern the eigen-values/vectors. We'll see that Funk SVD will work for missing values.\n",
    "\n",
    "<center><img src=\"mat_fact_17.png\" width=500></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVD CLosed Form Solution\n",
    "\n",
    "**What Is A Closed Form Solution?**<br>\n",
    "A closed form solution is one where you can directly find the solution values (unlike iterative solutions, which are commonly used in practice). There isn't an iterative approach to solving a particular equation. One of the most popular examples of a closed form solution is the solution for multiple linear regression. That is if we want to find an estimate for $\\beta$ in the following situation: $y=X\\beta$\n",
    "\n",
    "We can find it by computing the **Best Linear Unbiased Estimate (BLUE)**. It can found **in closed form** using the equation: $\\hat{\\beta}=\\left(X^{T}X \\right)^{-1}X^{T}y$\n",
    "\n",
    "Where **X** is a matrix of explanatory inputs and **y** is a response vector.\n",
    "\n",
    "Another common example of a closed form solution is the quadratic equation. If we want to find **x** that solves: $ax^{2}+bx+c=0$\n",
    "\n",
    "We can find these values using the quadratic formula: $x= \\frac{-b \\pm \\sqrt{ b^{2} - 4ac}}{2a}$\n",
    "\n",
    "**Each of these is an example of a closed form solution, because in each case we have an equation that allows us to solve directly for our values of interest.**\n",
    "\n",
    "**Closed Form Solutions for SVD**\n",
    "It turns out there is a closed form solution for Singular Value Decomposition that can be used to identify each of the matrices of interest ($U,\\Sigma,V$). The most straightforward explanation of this closed form solution can be found at [this MIT link](http://web.mit.edu/be.400/www/SVD/Singular_Value_Decomposition.htm).\n",
    "\n",
    "As put in the paper -\n",
    "\n",
    "\"Calculating the SVD consists of finding the eigenvalues and eigenvectors of $AA^{T}$ and $A^{T}A$. The eigenvectors of $A^{T}A$ make up the columns of $V$, the eigenvectors of $AA^{T}$ make up the columns of $U$. Also, the singular values in $\\Sigma$ are square roots of eigenvalues from $AA^{T}$ or $A^{T}A$. The singular values are the diagonal entries of the $\\Sigma$ matrix and are arranged in descending order. The singular values are always real numbers. If the matrix $A$ is a real matrix, then $U$ and $V$ are also real\"\n",
    "\n",
    "Again, you can see a fully worked example of the closed form solution at the [MIT link here](http://web.mit.edu/be.400/www/SVD/Singular_Value_Decomposition.htm).\n",
    "\n",
    "**A More Common Approach**\n",
    "The main issue with the closed form solution (especially for us) is that it doesn't actually work when we have missing data. Instead, Simon Funk (and then many followers) came up with other solutions for finding our matrices of interest in these cases using **gradient descent**.\n",
    "\n",
    "So all of this is to say, people don't really use the closed form solution for SVD, and therefore, we aren't going to spend a lot of time on it either. The link above is all you need to know. Now, we are going to look at the main way that the matrices in SVD are estimated, as this is what is used for estimating values in FunkSVD.\n",
    "\n",
    "**Additional Resources**\n",
    "Below are some additional resources in case you are looking for others that go beyond what was shown in the simplified MIT paper.\n",
    "* [Stanford Discussion on SVD](http://infolab.stanford.edu/~ullman/mmds/ch11.pdf)\n",
    "* [Why are Singular Values Always Positive on StackExchange](https://math.stackexchange.com/questions/2060572/why-are-singular-values-always-non-negative)\n",
    "* [An additional resource for SVD in Python](https://machinelearningmastery.com/singular-value-decomposition-for-machine-learning/)\n",
    "* [Using Missing Values to Improve Recommendations in SVD](https://www.hindawi.com/journals/mpe/2015/380472/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_ud",
   "language": "python",
   "name": "venv_ud"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
